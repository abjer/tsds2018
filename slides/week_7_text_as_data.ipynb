{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import dependencies\n",
    "import nltk\n",
    "#nltk.download('all') # Uncomment this and run\n",
    "\n",
    "import re,gensim,spacy\n",
    "\n",
    "# start downloading the data we are gonna be using today.\n",
    "# Look up the Enron scandal: https://en.wikipedia.org/wiki/Enron_scandal\n",
    "# Find details about the dataset here: https://www.cs.cmu.edu/~./enron/\n",
    "# and here https://data.world/brianray/enron-email-dataset\n",
    "import pandas as pd\n",
    "#enron_link ='https://query.data.world/s/boypyv5j5ey55s3mgevys7hbz3halo' \n",
    "#enron_df = pd.read_csv(enron_link)\n",
    "#enron_df.to_csv('enron_data.csv',index=False) \n",
    "enron_df = pd.read_csv('enron_data.csv')\n",
    "enron_df = enron_df[enron_df.content.apply(type)==str] # filter non strings\n",
    "enron_categories = []\n",
    "for cat in range(1,13):\n",
    "    for level in range(1,3):\n",
    "        category = 'Cat_%d_level_%d'%(cat,level)\n",
    "        if category in enron_df.columns:\n",
    "            enron_categories.append(category)\n",
    "enron_df = enron_df[[col for col in enron_df.columns if not col in enron_categories and 'weight' not in col]]\n",
    "# pip install -U git+git://github.com/Computational-Content-Analysis-2018/lucem_illud.git\n",
    "# For an implementation of the stanford corenlp, uncomment this: import lucem_illud \n",
    "import lucem_illud\n",
    "lucem_illud.setupStanfordNLP()\n",
    "import lucem_illud.stanford as stanford"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Corruption, Money and Power <center> \n",
    "![](http://media.economist.com/sites/default/files/cf_images/GA/2002w04/CGA229.gif)\n",
    "![](http://i.dailymail.co.uk/i/pix/2011/12/08/article-2071852-0F1BE2BF00000578-966_468x383.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**<center>Text as Data</center>**\n",
    "***<center>Information Extraction, Exploration and Prototyping</center>***\n",
    "\n",
    "<center>Snorre Ralund</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](http://3.bp.blogspot.com/-H5EfLEMD7gs/VU0R6T0cR5I/AAAAAAAABeA/3tTzaqPYdRw/s1600/desmazieres-borges-library-of-babel.jpg)\n",
    "\n",
    "Information about what people do, think, and feel lies embedded in text. Much of our social activity and communication is now done natively via text. The internet is full of information stored in text, and textual traces range from social media, emails and instant messaging, to automatically transcribed videos from youtube or memos from doctors, goverment records and digitized libraries. \n",
    "\n",
    "This vast supply of text has broad demand for natural language processing and machine learning tools to filter, search, and translate text into valuable data.\n",
    "\n",
    "And it has broad exciting opportunities for social scientists who knows how to get and handle text as data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "** Examples **\n",
    "* Chen 2013: *\"The effects of language on Economic Behaviour - Evidence from Savings Rates, Health Behaviors, and Retirement Assets\"*\n",
    "    * Quantifying the use of future tense in different languages and its connection to future oriented behavior: saving for retirement, practicing safe sex etc.\n",
    "* Gentzkow and Shapiro 2007: *\"What drives media slant? Evidence from U.S daily newspapers\"*\n",
    "\n",
    "*  Danescu-Niculescu-M et. al 20xx [*\"Echoes of Power: Language Effects and Power Differences in Social Interaction\"*](https://www.cs.cornell.edu/%7Ecristian/Echoes_of_power_files/echoes_of_power.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Agenda**\n",
    "\n",
    "Today I want you to get your hands dirty with manipulating and handling text in python.\n",
    "\n",
    "Before we start creating our own custom models to process text, I want you to get a good feeling with the off-the-shelf-tools available as well as basic processing of text you can do with python.\n",
    "\n",
    "We are gonna focus on **Information Extraction**\n",
    "\n",
    "and **Exploration**.\n",
    "\n",
    "\n",
    "This means developing the skills to do efficient exploratory analysis of text. \n",
    "\n",
    "While the generic tools I will be presenting are very powerful, it is however important from a scientific perspective, to stress that they serve mainly in the initial phase, as **Protyping** results.\n",
    "\n",
    "This is great, and for many purposes enough, but the next to sessions we shall focus on creating custom and more ***transparent*** and ***reliable*** models process text data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "** Headlines **\n",
    "* Text normalization, and representation.\n",
    "* Information extraction\n",
    "    * String Pattern extraction with regular expressions.\n",
    "    * Lexical methods.\n",
    "    * Model based information extraction.\n",
    "* Sentiment analysis\n",
    "* Part-of-tagging, named-entity-recognition.\n",
    "* Document Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# String operations with python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "of course you already now your basics:\n",
    "\n",
    "`string.split\n",
    "string.strip\n",
    "string.replace`\n",
    "\n",
    "And sometimes this will be enough, but sometimes it is not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Regular Expressions\n",
    "![](https://cdn-images-1.medium.com/max/800/0*j1f-EFL7TDtf6K0o.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Regex can be a little terrifying:\n",
    "\n",
    "`pattern = '(?:(?:\\r\\n)?[ \\t])*(?:(?:(?:[^()<>@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()<>@,;:\\\\\".\\[\\]]))|\"(?:[^\\\"\\r\\\\]|\\\\.|(?:(?:\\r\\n)?[ \\t]))*\"(?:(?:\\r\\n)?[ \\t])*)(?:\\.(?:(?:\\r\\n)?[ \\t])*(?:[^()<>@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()<>@,;:\\\\\".\\[\\]]))|\"(?:[^\\\"\\r\\\\]|\\\\.|(?:(?:\\r\\n)?[ \\t]))*\"(?:(?:\\r\\n)?[ \\t])*))*@(?:(?:\\r\\n)?[ \\t])*(?:[^()<>@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()<>@,;:\\\\\".\\[\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[ \\t])*)(?:\\.(?:(?:\\r\\n)?[ \\t])*(?:[^()<>@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()<>@,;:\\\\\".\\[\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[ \\t])*))*|(?:[^()<>@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()<>@,;:\\\\\".\\[\\]]))|\"(?:[^\\\"\\r\\\\]|\\\\.|(?:(?:\\r\\n)?[ \\t]))*\"(?:(?:\\r\\n)?[ \\t])*)*\\<(?:(?:\\r\\n)?[ \\t])*(?:@(?:[^()<>@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()<>@,;:\\\\\".\\[\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[ \\t])*)(?:\\.(?:(?:\\r\\n)?[ \\t])*(?:[^()<>@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()<>@,;:\\\\\".\\[\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[ \\t])*))*(?:,@(?:(?:\\r\\n)?[ \\t])*(?:[^()<>@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()<>@,;:\\\\\".\\[\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[ \\t])*)(?:\\.(?:(?:\\r\\n)?[ \\t])*(?:[^()<>@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()<>@,;:\\\\\".\\[\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[ \\t])*))*)*:(?:(?:\\r\\n)?[ \\t])*)?(?:[^()<>@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()<>@,;:\\\\\".\\[\\]]))|\"(?:[^\\\"\\r\\\\]|\\\\.|(?:(?:\\r\\n)?[ \\t]))*\"(?:(?:\\r\\n)?[ \\t])*)(?:\\.(?:(?:\\r\\n)?[ \\t])*(?:[^()<>@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()<>@,;:\\\\\".\\[\\]]))|\"(?:[^\\\"\\r\\\\]|\\\\.|(?:(?:\\r\\n)?[ \\t]))*\"(?:(?:\\r\\n)?[ \\t])*))*@(?:(?:\\r\\n)?[ \\t])*(?:[^()<>@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()<>@,;:\\\\\".\\[\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[ \\t])*)(?:\\.(?:(?:\\r\\n)?[ \\t])*(?:[^()<>@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()<>@,;:\\\\\".\\[\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[ \\t])*))*\\>(?:(?:\\r\\n)?[ \\t])*)|(?:[^()<>@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()<>@,;:\\\\\".\\[\\]]))|\"(?:[^\\\"\\r\\\\]|\\\\.|(?:(?:\\r\\n)?[ \\t]))*\"(?:(?:\\r\\n)?[ \\t])*)*:(?:(?:\\r\\n)?[ \\t])*(?:(?:(?:[^()<>@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()<>@,;:\\\\\".\\[\\]]))|\"(?:[^\\\"\\r\\\\]|\\\\.|(?:(?:\\r\\n)?[ \\t]))*\"(?:(?:\\r\\n)?[ \\t])*)(?:\\.(?:(?:\\r\\n)?[ \\t])*(?:[^()<>@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()<>@,;:\\\\\".\\[\\]]))|\"(?:[^\\\"\\r\\\\]|\\\\.|(?:(?:\\r\\n)?[ \\t]))*\"(?:(?:\\r\\n)?[ \\t])*))*@(?:(?:\\r\\n)?[ \\t])*(?:[^()<>@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()<>@,;:\\\\\".\\[\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[ \\t])*)(?:\\.(?:(?:\\r\\n)?[ \\t])*(?:[^()<>@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()<>@,;:\\\\\".\\[\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[ \\t])*))*|(?:[^()<>@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()<>@,;:\\\\\".\\[\\]]))|\"(?:[^\\\"\\r\\\\]|\\\\.|(?:(?:\\r\\n)?[ \\t]))*\"(?:(?:\\r\\n)?[ \\t])*)*\\<(?:(?:\\r\\n)?[ \\t])*(?:@(?:[^()<>@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()<>@,;:\\\\\".\\[\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[ \\t])*)(?:\\.(?:(?:\\r\\n)?[ \\t])*(?:[^()<>@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()<>@,;:\\\\\".\\[\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[ \\t])*))*(?:,@(?:(?:\\r\\n)?[ \\t])*(?:[^()<>@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()<>@,;:\\\\\".\\[\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[ \\t])*)(?:\\.(?:(?:\\r\\n)?[ \\t])*(?:[^()<>@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()<>@,;:\\\\\".\\[\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[ \\t])*))*)*:(?:(?:\\r\\n)?[ \\t])*)?(?:[^()<>@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()<>@,;:\\\\\".\\[\\]]))|\"(?:[^\\\"\\r\\\\]|\\\\.|(?:(?:\\r\\n)?[ \\t]))*\"(?:(?:\\r\\n)?[ \\t])*)(?:\\.(?:(?:\\r\\n)?[ \\t])*(?:[^()<>@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()<>@,;:\\\\\".\\[\\]]))|\"(?:[^\\\"\\r\\\\]|\\\\.|(?:(?:\\r\\n)?[ \\t]))*\"(?:(?:\\r\\n)?[ \\t])*))*@(?:(?:\\r\\n)?[ \\t])*(?:[^()<>@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()<>@,;:\\\\\".\\[\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[ \\t])*)(?:\\.(?:(?:\\r\\n)?[ \\t])*(?:[^()<>@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()<>@,;:\\\\\".\\[\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[ \\t])*))*\\>(?:(?:\\r\\n)?[ \\t])*)(?:,\\s*(?:(?:[^()<>@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()<>@,;:\\\\\".\\[\\]]))|\"(?:[^\\\"\\r\\\\]|\\\\.|(?:(?:\\r\\n)?[ \\t]))*\"(?:(?:\\r\\n)?[ \\t])*)(?:\\.(?:(?:\\r\\n)?[ \\t])*(?:[^()<>@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()<>@,;:\\\\\".\\[\\]]))|\"(?:[^\\\"\\r\\\\]|\\\\.|(?:(?:\\r\\n)?[ \\t]))*\"(?:(?:\\r\\n)?[ \\t])*))*@(?:(?:\\r\\n)?[ \\t])*(?:[^()<>@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()<>@,;:\\\\\".\\[\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[ \\t])*)(?:\\.(?:(?:\\r\\n)?[ \\t])*(?:[^()<>@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()<>@,;:\\\\\".\\[\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[ \\t])*))*|(?:[^()<>@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()<>@,;:\\\\\".\\[\\]]))|\"(?:[^\\\"\\r\\\\]|\\\\.|(?:(?:\\r\\n)?[ \\t]))*\"(?:(?:\\r\\n)?[ \\t])*)*\\<(?:(?:\\r\\n)?[ \\t])*(?:@(?:[^()<>@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()<>@,;:\\\\\".\\[\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[ \\t])*)(?:\\.(?:(?:\\r\\n)?[ \\t])*(?:[^()<>@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()<>@,;:\\\\\".\\[\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[ \\t])*))*(?:,@(?:(?:\\r\\n)?[ \\t])*(?:[^()<>@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()<>@,;:\\\\\".\\[\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[ \\t])*)(?:\\.(?:(?:\\r\\n)?[ \\t])*(?:[^()<>@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()<>@,;:\\\\\".\\[\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[ \\t])*))*)*:(?:(?:\\r\\n)?[ \\t])*)?(?:[^()<>@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()<>@,;:\\\\\".\\[\\]]))|\"(?:[^\\\"\\r\\\\]|\\\\.|(?:(?:\\r\\n)?[ \\t]))*\"(?:(?:\\r\\n)?[ \\t])*)(?:\\.(?:(?:\\r\\n)?[ \\t])*(?:[^()<>@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()<>@,;:\\\\\".\\[\\]]))|\"(?:[^\\\"\\r\\\\]|\\\\.|(?:(?:\\r\\n)?[ \\t]))*\"(?:(?:\\r\\n)?[ \\t])*))*@(?:(?:\\r\\n)?[ \\t])*(?:[^()<>@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()<>@,;:\\\\\".\\[\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[ \\t])*)(?:\\.(?:(?:\\r\\n)?[ \\t])*(?:[^()<>@,;:\\\\\".\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[\"()<>@,;:\\\\\".\\[\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[ \\t])*))*\\>(?:(?:\\r\\n)?[ \\t])*))*)?;\\s*)'`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "It is extremely valuable when working with any kind of text, for searching, extracting and substituting specific patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Example\n",
    "Lets imagine we were hackers trying to break into computers in our network. \n",
    "\n",
    "First we would need a way to search for the possible machines. \n",
    "Regular expressions to the rescue..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ant-2y5tlh2.samf.domain (192.38.122.169) at a4:4c:c8:ee:7e:06 [ether] on eno1\\n? (192.38.122.1) at 00:1f:ca:f8:2b:c9 [ether] on eno1\\n? (192.38.122.232) at 68:5b:35:a9:2c:d7 [ether] on eno1\\n? (192.38.122.97) at 68:5b:35:a9:2c:d7 [ether] on eno1\\n? (192.38.122.151) at 00:23:24:7c:93:ea [ether] on eno1\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "ip_lookup = os.popen('arp -a').read()\n",
    "ip_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a4:4c:c8:ee:7e:06', '192.38.122.169'),\n",
       " ('00:1f:ca:f8:2b:c9', '192.38.122.1'),\n",
       " ('68:5b:35:a9:2c:d7', '192.38.122.232'),\n",
       " ('68:5b:35:a9:2c:d7', '192.38.122.97'),\n",
       " ('00:23:24:7c:93:ea', '192.38.122.151')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "#mac_add = '(([0-9a-f]{2}\\:){5}[0-9a-f]{2})'\n",
    "#macs = [i[0] for i in re.findall(mac_add,ip_lookup)]\n",
    "mac_add = '([a-f0-9\\:]{17})'\n",
    "macs = re.findall(mac_add,ip_lookup)\n",
    "\n",
    "ip_pattern = '([0-9\\.]{9,})'\n",
    "ips = re.findall(ip_pattern,ip_lookup)\n",
    "list(zip(macs,ips))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "** Regular Expression syntax **\n",
    "\n",
    "Ressources:\n",
    "\n",
    "Play around with it [here](http://regexr.com/) or in this notebook.\n",
    "\n",
    "Lookup all special characters [here](https://www.regular-expressions.info/refquick.html)\n",
    "\n",
    "* \\+ = 1 or more times\n",
    "* \\* = 0 or more times\n",
    "* {3} = exactly three times\n",
    "* ? = once or none\n",
    "* (?=)\t= Positive lookahead\n",
    "* (?!)\t= Negative lookahead\n",
    "* (?<=)\t= Positive lookbehind\n",
    "* (?<!) = Negative lookbehind\n",
    "* \\\\ = escape character, used to find characters that has special meaning with regex: e.g. \\+ \\*\n",
    "* () = defining a the match group: i.e. within the paranthesis is the pattern I care about.\n",
    "* [] = set of characters\n",
    "* ^ = applied within a set, it becomes the inverse of the set defined.\n",
    "* . = any characters except line break\n",
    "* | = or statement. p|b find characters a or b.\n",
    "* \\d = digits\n",
    "* \\D = any-non-digits.\n",
    "* \\s = whitespace-separator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Regular expressions (2): define - inspect - refine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def explore_regex(pattern,string_sample,n_output=10,before=10,after=10,shuffle=False):\n",
    "    count = 0\n",
    "    import random\n",
    "    length = len(string_sample)\n",
    "    \n",
    "    results = list(enumerate(re.finditer(pattern,string_sample)))\n",
    "    \n",
    "    if shuffle:\n",
    "        random.shuffle(results)\n",
    "    indices,results = zip(*results)\n",
    "    for result in results:\n",
    "        start,stop = result.span()\n",
    "        temp_after = min([length-stop,after])\n",
    "        temp_before = min([start,before])\n",
    "        print('Matched: %s\\tContext:%s'%(result.group(),string_sample[start-temp_before:stop+temp_after]))\n",
    "        count+=1\n",
    "        if count>n_output:\n",
    "            break\n",
    "    return [result.group() for result in results]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### email example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Thanks for the info. I appreciated the call the other day. It really helps me out to recieve info early like that. D From: Mary Jo Johnson 11/20/2000 03:38 PM To: Daren J Farmer/HOU/ECT@ECT, James McKay/HOU/ECT@ECT, Gary A Hanks/HOU/ECT@ECT cc: Jill T Zivley/HOU/ECT@ECT Subject: HILCORP old ocean volume According to Gary Hanks, we would like to have the gas on the valley line anyway ---------------------- Forwarded by Mary Jo Johnson/HOU/ECT on 11/20/2000 03:26 PM --------------------------- To: Jill T Zivley/HOU/ECT@ECT cc: Edward D Gottlob/HOU/ECT@ECT, Lauri A Allen/HOU/ECT@ECT Subject: Re: Producer service group? I can not believe you are sending emails form Hawaii!!!! You are crazy. I took care of Camden for the month- It is now 330 and Hilcorp has not responded. I spoke with Jerry Bubert several times today- emailed Mike LAnnou and left messages, and had him paged, and copied Hildebrand (the president). If we don't hear by 4pm, we are supposed to bypass the gas...........\\nGuys: We\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First lets look at a sample\n",
    "sample_string = '\\n'.join(enron_df.sample(50).content) # the sample function is very nice for your workflow.\n",
    "sample_string[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched: <lgoldseth@svmg.org>\tContext:Goldseth\" <lgoldseth@svmg.org> 04/26/200\n",
      "Matched: <lgoldseth@svmg.org>\tContext:11 PM To: <lgoldseth@svmg.org> cc: Subje\n",
      "Matched: mcausholli@hotmail.com\tContext: 807-1039 mcausholli@hotmail.com (preferre\n",
      "Matched: Causey/Corp/Enron@ENRON,\tContext:: Richard Causey/Corp/Enron@ENRON, Sally Bec\n",
      "Matched: Beck/HOU/ECT@ECT\tContext:ON, Sally Beck/HOU/ECT@ECT cc: Subje\n",
      "Matched: Beck/HOU/ECT@ECT,\tContext:To: Sally Beck/HOU/ECT@ECT, Richard C\n",
      "Matched: Causey/Corp/Enron@ENRON,\tContext:, Richard Causey/Corp/Enron@ENRON, Gene Hump\n",
      "Matched: Humphrey/Enron@EnronXGate,\tContext:RON, Gene Humphrey/Enron@EnronXGate, Wanda Cur\n",
      "Matched: Curry/HOU/EES@EES,\tContext:te, Wanda Curry/HOU/EES@EES, Brent A P\n",
      "Matched: Price/Enron@EnronXGate,\tContext:, Brent A Price/Enron@EnronXGate, Charlene \n",
      "Matched: Jackson/Corp/Enron@ENRON,\tContext: Charlene Jackson/Corp/Enron@ENRON, Christie \n",
      "\n",
      "New Pattern: [0-9A-Za-z_\\.\\-]+@[\\.0-9A-Za-z]+\n",
      "Matched: lgoldseth@svmg.org\tContext:oldseth\" <lgoldseth@svmg.org> 04/26/20\n",
      "Matched: lgoldseth@svmg.org\tContext:1 PM To: <lgoldseth@svmg.org> cc: Subj\n",
      "Matched: mcausholli@hotmail.com\tContext: 807-1039 mcausholli@hotmail.com (preferre\n",
      "Matched: Enron@ENRON\tContext:usey/Corp/Enron@ENRON, Sally Be\n",
      "Matched: ECT@ECT\tContext: Beck/HOU/ECT@ECT cc: Subje\n",
      "Matched: ECT@ECT\tContext: Beck/HOU/ECT@ECT, Richard \n",
      "Matched: Enron@ENRON\tContext:usey/Corp/Enron@ENRON, Gene Hum\n",
      "Matched: Enron@EnronXGate\tContext: Humphrey/Enron@EnronXGate, Wanda Cu\n",
      "Matched: EES@EES\tContext:Curry/HOU/EES@EES, Brent A \n",
      "Matched: Enron@EnronXGate\tContext:t A Price/Enron@EnronXGate, Charlene\n",
      "Matched: Enron@ENRON\tContext:kson/Corp/Enron@ENRON, Christie\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Beck/HOU/ECT@ECT',\n",
       " 'Kingerski/NA/Enron@Enron,',\n",
       " 'Lowry/HOU/ECT@ECT,',\n",
       " 'mailto:abb@eslawfirm.com',\n",
       " 'Woods/DUB/EES@EES,',\n",
       " 'Shapiro/NA/Enron@ENRON,',\n",
       " 'Bowen/HOU/ECT@ECT',\n",
       " 'Thompson/HOU/ECT@ECT,',\n",
       " 'McMahon/HOU/ECT@ECT,',\n",
       " 'Benevides/HOU/EES@EES,']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_string = '\\n'.join(enron_df.sample(50).content)\n",
    "email_pattern = '@' # start defining a very broad one\n",
    "email_pattern = '[^\\s]+@[^\\s]+' # narrow it a little..  \\S = [^\\s]\n",
    "results1 = explore_regex(email_pattern,sample_string) \n",
    "email_pattern2 = '[0-9A-Za-z_\\.\\-]+@[\\.0-9A-Za-z]+' # refine\n",
    "print('\\nNew Pattern: %s'%email_pattern2)\n",
    "results2 = explore_regex(email_pattern2,sample_string)\n",
    "list(set(results1)-set(results2))[0:10] # inspect divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RE_EMAIL = '[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+'#'[\\b<][a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+[\\b>]'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "** Exercises **\n",
    "\n",
    "***Ex. 1.1***\n",
    "* Load the Enron email dataset and start mining numbers mentioned in the emails.\n",
    "    * Both literal numbers (millions,billions etc) and digits.\n",
    "    * Match currencies $ and percentages %\n",
    "* Rank the people talking most about numbers.\n",
    "\n",
    "***Ex. 1.2***\n",
    "* Find names mentioned in the emails. - i.e. marked by Capital letters that did not follow punctuation and newlines.\n",
    "    * This is a really hard task, so don't worry that it won't be perfect, it is just to get a feel of the task of extracting Entities from text.\n",
    "* Which names are mentioned the most, and which people talk most about who?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your answer goes here or in the exercise notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# From raw text to words and numbers\n",
    "## ... fortunatly we don't have to write everything in regex ourselves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "** Preprocessing **\n",
    "* Word tokenization and sentence detection\n",
    "    * the need can vary alot (social media, to old prose, and ocr based goverment documents.)\n",
    "* Ngram / skipgram / Collocations\n",
    "* Stemming / Lemmatization\n",
    "* Stopword remowal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Tokenizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Lets get some real native text.\n",
    "import requests\n",
    "qs = ['math','hard','sucks','ass','text','data','bitch']\n",
    "q = 'http://deepbeat.org/deepbeat.fcgi?l=en&nn=true&k=&m=multi'+'&q='.join(qs) # found using the network monitor.\n",
    "#original = 'http://deepbeat.org/deepbeat.fcgi?l=en&nn=true&k=&m=multi&q=math&q=sucks&q=&q=&q=&q=&q=&q=&q='\n",
    "lyrics = requests.get(q).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey Ja Joey\n",
      "Legally and illegally\n",
      "Trouble comes naturally\n",
      "'' Bridge ''\n",
      "Uh really. Totally.\n",
      "Blood start flowing\n",
      "It's so lonelly\n",
      "Man I need Maui Wowie\n",
      "See cause usually\n",
      "Just like a hillbilly\n",
      "I will literally\n",
      "I smoke that Maui Wowie\n",
      "Snatch the gat brr-at! And lyrically wreck that ass officially\n",
      "I need Maui Wowie\n",
      "And bullshit usually\n",
      "I know you especially\n",
      "And acting unrationally\n",
      "I'll get my swagger goin'\n",
      "They want me chronally\n",
      "Breakfast at Papa Deaux's\n"
     ]
    }
   ],
   "source": [
    "rhymes = '\\n'.join([i['line'] for i in lyrics['rhymes']])\n",
    "print(rhymes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#rhymes.split()\n",
    "#nltk.word_tokenize(rhymes)\n",
    "#nltk.sent_tokenize(rhymes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "so it can parse tough rap lyrics. But what about **emotions**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[':p', '<3', '<3', ':)', ':)', ':(', '<3', ':/', ':-/', ':|', ':p']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# practice emojiis here https://regexr.com/3a8o5\n",
    "import re\n",
    "pattern = '\\:\\)|\\:\\(|<3|\\:\\/(?!\\/)|\\:-\\/|\\:\\||\\:p(?![a-z])|\\:\\-\\)' # see nltk.sentiment.util.EMOTICON_RE for a more professional implementation\n",
    "emoticon_string = ''':p - that should match!\n",
    "no matches here: http://example.com\n",
    "* We don\\'t watch to match inside other :pencil: emoji syntax either\n",
    "* Probably shouldn\\'t match this `for (var i=0; i<3; i++){}`\n",
    "* This should match - I love (<3) Regular Expressions!\n",
    "* some code shouldn\\'t match: `<tag:person />`\n",
    ":) SO HAPPY\n",
    "\n",
    "\n",
    "===========================\n",
    "All emoticons listed out.\n",
    "these should always match!\n",
    ":) :( <3 :/ :-/ :| :p\n",
    "==========================='''\n",
    "re.findall(pattern,emoticon_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#nltk.word_tokenize(emoticon_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Implementation in a tokenizer here:\n",
    "nltk.sentiment.vader.SentiText(emoticon_string).words_and_emoticons\n",
    "# If that doesn't work look at Bjarke Felbos work DeepMoji: https://github.com/bfelbo/DeepMoji/blob/master/deepmoji/tokenizer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%timeit emotion_string.split()\n",
    "%timeit nltk.word_tokenize(emotion_string)\n",
    "%timeit nltk.sentiment.vader.SentiText(emoticon_string).words_and_emoticons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Preprocessing(2)\n",
    "Stemming, lemmatizing, stopwords, and non-digit words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000 loops, best of 3: 13.5 Âµs per loop\n",
      "The slowest run took 6.35 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "1000000 loops, best of 3: 661 ns per loop\n",
      "The slowest run took 7.20 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "1000000 loops, best of 3: 287 ns per loop\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words_nltk = set(stopwords.words('english')) # remember to define as set for performance\n",
    "stop_words_list = stopwords.words('english')\n",
    "own_stop_words = set([\"the\",\"it\",\"she\",\"he\", \"a\",\"trump\",'idiot','failure','weak']) # Define your own list of stopwords\n",
    "\n",
    "%timeit [w for w in own_stop_words if w not in stop_words_list]\n",
    "%timeit [w for w in own_stop_words if w not in stop_words_nltk]\n",
    "%timeit own_stop_words&stop_words_nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#The stemmers and lemmers need to be initialized before being run\n",
    "porter = nltk.stem.porter.PorterStemmer() # \n",
    "snowball = nltk.stem.snowball.SnowballStemmer('english') # a greedy stripper\n",
    "wordnet = nltk.stem.WordNetLemmatizer()\n",
    "def normalize_tokens(tokens,lowercase=False\n",
    "                     ,remove_non_alpha=False\n",
    "                     , stopwords = False\n",
    "                     , stemmer = False\n",
    "                     , lemmer = False):\n",
    "    #We can use a generator here as we just need to iterate over it\n",
    "    workingIter = tokens\n",
    "    #removing non-words\n",
    "    if remove_non_alpha:\n",
    "        workingIter = (w for w in workingIter if w.isalpha())\n",
    "    \n",
    "    # lowering\n",
    "    if lowercase:\n",
    "        workingIter = (w.lower() for w in workingIter)\n",
    "    #Now we can use the semmer, if provided\n",
    "    if stemmer:\n",
    "        workingIter = (stemmer.stem(w) for w in workingIter)\n",
    "        \n",
    "    #And the lemmer\n",
    "    if lemmer:\n",
    "        workingIter = (lemmer.lemmatize(w) for w in workingIter)\n",
    "    \n",
    "    #And remove the stopwords\n",
    "    if stopwords:\n",
    "        workingIter = (w for w in workingIter if w not in stopwords)\n",
    "    #We will return a list with the stopwords removed\n",
    "    return list(workingIter)\n",
    "'state-of-the-art'.isalpha()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Lets apply this to our email dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                           [forecast]\n",
       "1    [traveling, business, meeting, take, fun, trip...\n",
       "2                          [test, successful, way, go]\n",
       "3    [randy, send, schedule, salary, level, everyon...\n",
       "4                                [let, shoot, tuesday]\n",
       "5     [greg, either, next, tuesday, thursday, phillip]\n",
       "6    [please, cc, following, distribution, list, up...\n",
       "7                                            [morning]\n",
       "8    [login, pallen, pw, think, required, isp, stat...\n",
       "9    [forwarded, phillip, k, pm, buckner, buck, pm,...\n",
       "Name: content, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kwargs = {'lowercase':True\n",
    "        ,'remove_non_alpha':True,\n",
    "        'stopwords':stop_words_nltk,\n",
    "        'stemmer':False,'lemmer':wordnet}\n",
    "enron_df.iloc[0:10].content.apply(nltk.word_tokenize).apply(normalize_tokens\n",
    "                                                            ,**kwargs)#.apply(len)#apply(lambda x: len(set(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ngrams / SkipGrams and Collocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigrams\n",
      "[(' ', 62088), ('e', 35372), ('t', 25295), ('a', 24125), ('o', 21971), ('i', 20612), ('n', 20013), ('r', 19237), ('s', 18994), ('l', 12813), ('h', 11274), ('d', 10159), ('c', 9812), ('u', 7774), ('m', 7409), ('p', 6440), ('g', 6232), ('f', 5759), ('y', 5398), ('0', 5372)]\n",
      "\n",
      "BIGRAMS:\n",
      "[('e ', 9130), (' t', 7373), ('s ', 6495), ('th', 5810), ('er', 5347), ('he', 5156), (' a', 4857), ('t ', 4627), ('in', 4621), ('d ', 4488)]\n",
      "\n",
      "Trigrams:\n",
      "[(' th', 4731), ('the', 3777), ('20 ', 3516), ('he ', 3496), ('=20', 3489), ('ed ', 1857), (' to', 1819), ('ing', 1791), ('to ', 1618), ('er ', 1582)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "#string_sample = ' '.join(enron_df.sample(100).content)\n",
    "sequence = string_sample # rhymes\n",
    "n = 1\n",
    "unigrams = Counter([sequence[i:i+n] for i in range(len(sequence)-n)])\n",
    "print('Unigrams')\n",
    "print(unigrams.most_common(20))\n",
    "n = 2 \n",
    "bigrams = Counter([sequence[i:i+n] for i in range(len(sequence)-n)])\n",
    "print('\\nBIGRAMS:')\n",
    "print(bigrams.most_common(10))\n",
    "n = 3\n",
    "trigrams = Counter([sequence[i:i+n] for i in range(len(sequence)-n)])\n",
    "print('\\nTrigrams:')\n",
    "print(trigrams.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Skipgram:\n",
      "[(('Subject', '-', '-', '-', 'Analyst', 'program', 'needs', 'you'), 3), (('By', '-', '-', '-', 'Daily', 'News', 'Published', 'January'), 3), (('Jeff', '-', '-', '-', 'great', 'idea', 'Thanks', 'for'), 2), (('Sue', '-', '-', '-', 'Fax', 'Forwarded', 'by', 'Susan'), 2), (('Mara', '-', '-', '-', 'Forwarded', 'by', 'Susan', 'J'), 2), (('Enron', '-', '-', '-', 'by', 'Susan', 'J', 'on'), 2), (('Tel', '-', '-', '-', 'Susan', 'J', 'on', 'AM'), 2), (('Forwarded', '-', '-', '-', 'AM', 'From', 'Althea', 'Gordon'), 2), (('by', '-', '-', '-', 'From', 'Althea', 'Gordon', 'AM'), 2), (('cc', '-', '-', '-', 'and', 'Analyst', 'program', 'needs'), 2)]\n"
     ]
    }
   ],
   "source": [
    "# With sligth modification we can change it to do Word-based ngrams + skip.\n",
    "skip = 4 \n",
    "n = 4\n",
    "sequence = ''.join([i.lower() for i in ' '.join(enron_df.sample(100).content) if i.isalpha()])\n",
    "sequence = [i for i in normalize_tokens(nltk.word_tokenize(' '.join(enron_df.sample(100).content))) if i.isalpha()]\n",
    "bigrams = Counter(map(tuple,[[sequence[i]]+['-']*(skip-1)+sequence[i+skip:i+skip+n] for i in range(len(sequence[::skip])-(n+skip))]))\n",
    "print('\\nSkipgram:')\n",
    "print(bigrams.most_common(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 53.7 ms per loop\n",
      "10 loops, best of 3: 112 ms per loop\n"
     ]
    }
   ],
   "source": [
    "def find_ngrams(sentence, n):\n",
    "    return Counter(zip(*[sentence[i:] for i in range(n)]))\n",
    "def find_ngrams2(sentence,n):\n",
    "    sequence = sentence\n",
    "    ngrams = Counter([sequence[i:i+n] for i in range(len(sequence)-n)])\n",
    "    return ngrams\n",
    "\n",
    "%timeit find_ngrams(string_sample,2)\n",
    "%timeit find_ngrams2(string_sample,2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "But do these ngrams carry new information not already captured by unigrams?\n",
    "\n",
    "This is the question that the analysis of **Collocations** address."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "bigrams_nltk = nltk.collocations.BigramCollocationFinder.from_words(normalize_tokens(nltk.word_tokenize(string_sample),remove_non_alpha=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('the', 'state'), 1100.2771170396554), (('Gov', 'Gray'), 552.4599329240316), (('PG', 'E'), 515.3614981642891), (('more', 'than'), 487.9573885343577), (('of', 'the'), 475.5636262816188), (('spot', 'market'), 459.8194752096102), (('Message', 'From'), 454.4625532655454), (('Gray', 'Davis'), 382.23969949385014), (('will', 'be'), 381.7073505058824), (('PM', 'To'), 353.0635786892882), (('Southern', 'California'), 335.9273787798102), (('Los', 'Angeles'), 330.46557708832546), (('San', 'Francisco'), 320.1798571113932), (('natural', 'gas'), 317.36167922815093), (('SDG', 'E'), 305.19660796712753), (('Regulatory', 'Commission'), 299.9497793133563), (('has', 'been'), 297.91841938071906), (('Water', 'Resources'), 292.98166169975667), (('Department', 'of'), 283.96199817230746), (('in', 'the'), 283.7455317900602), (('Energy', 'Regulatory'), 267.097281579992), (('San', 'Diego'), 261.5193490060009), (('Included', 'Inside'), 258.7476601552044), (('AM', 'To'), 256.6235737792331), (('Charges', 'Included'), 251.39975935136536)]\n",
      "[(('the', 'state'), 15.122401806763376), (('of', 'the'), 13.197296044544746), (('in', 'the'), 10.280778103100095), (('for', 'the'), 8.598728328370543), (('will', 'be'), 7.64593973792111), (('more', 'than'), 7.301336162675887), (('to', 'be'), 7.044207512069764), (('on', 'the'), 6.698167460029527), (('Department', 'of'), 6.308558809939814), (('spot', 'market'), 6.306470447720334), (('Gov', 'Gray'), 6.158366549165973), (('PG', 'E'), 6.156332405614054), (('at', 'the'), 6.134968347890571), (('has', 'been'), 6.026663886916707), (('by', 'the'), 6.012355658884259), (('Gray', 'Davis'), 5.977547869636435), (('would', 'be'), 5.888491108250257), (('Southern', 'California'), 5.8727471890741105), (('he', 'said'), 5.8587146268261705), (('of', 'Water'), 5.763581895282768), (('PM', 'To'), 5.726815004585962), (('said', 'he'), 5.685719436012203), (('that', 'the'), 5.620469915631722), (('Message', 'From'), 5.562678482268799), (('from', 'the'), 5.374684325306581), (('with', 'the'), 5.2704813647767565), (('have', 'been'), 5.207047171191115), (('to', 'pay'), 5.154396053790195), (('part', 'of'), 5.125491585121372), (('in', 'California'), 5.116600455632331), (('natural', 'gas'), 5.0896850457670295), (('would', 'have'), 5.0886259410714345), (('Duke', 'Energy'), 5.0733201876168135), (('San', 'Francisco'), 4.991968068081261), (('power', 'plant'), 4.984111033079535), (('and', 'other'), 4.981501730530807), (('energy', 'crisis'), 4.968663039180615), (('out', 'of'), 4.950506978545573), (('the', 'first'), 4.932367878937829), (('it', 'was'), 4.88393535581975)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['chi_sq',\n",
       " 'dice',\n",
       " 'fisher',\n",
       " 'jaccard',\n",
       " 'likelihood_ratio',\n",
       " 'mi_like',\n",
       " 'phi_sq',\n",
       " 'pmi',\n",
       " 'poisson_stirling',\n",
       " 'raw_freq',\n",
       " 'student_t']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_bigram(count, wordsTuple, total):\n",
    "    return count\n",
    "#print(bigrams.nbest(count_bigram,n=10))\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "print(bigrams_nltk.score_ngrams(bigram_measures.likelihood_ratio)[:25]) # likelihood of token a given token b / likelihood of token a\n",
    "#print(bigrams_nltk.score_ngrams(bigram_measures.raw_freq)[:25])\n",
    "#print([i for i in bigrams_nltk.score_ngrams(bigram_measures.jaccard) if i[1]!=1][0:25])\n",
    "print(bigrams_nltk.score_ngrams(bigram_measures.student_t)[:40])\n",
    "[s for s in dir(bigram_measures) if s[0] != '_']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Exercises**\n",
    "Ex.2.1\n",
    "* Print the colloction measure of all the matched person names found in using your own regex.\n",
    "* Replace the 10 names with the highest collocation measure, with a new identifier in the original string:\n",
    "    '/NAME/%s_%s__'%(collocation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#dict(bigrams_nltk.score_ngrams(bigram_measures.student_t)[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lexical approaches to information extraction\n",
    "With this approach we simply we simply compare text to a set of words curated to mean something specific.\n",
    "\n",
    "This approach is widely used for sentiment analysis, but can also be used for prototyping other measurements including political topics: e.g. ['Climate change','co2','Global warming'].  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Sentiment analysis\n",
    "Here we are gonna be comparing a few off-the-shelf lexical and rulebased approaches:\n",
    "\n",
    "* [Afinn (is danish!)](http://neuro.imm.dtu.dk/wiki/AFINN), \n",
    "* [Liu Hu (lexical)](http://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html) and \n",
    "* [Vader (lexical and rulebased)](https://github.com/cjhutto/vaderSentiment).\n",
    "\n",
    "* ** Purely Lexical ** Naively Matching positive words. *\"You are beautiful.\"* \n",
    "* ** Rule-based ** Can Adopt hard-coded rules to counter more or less simple negations. *\"You are not particularly beautiful.\"*\n",
    "\n",
    ".. still lacks the ability to understand that the connotations: *\"You are extremely beautiful on the outside.\"*\n",
    "\n",
    "* ** Modelbased ** Supervised Models trained to adopt many different expression of emotions: for some exciting ones lookup **DeepMoji**, or the so-called **sentiment neuron**. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spoon-fed'"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import opinion_lexicon\n",
    "negative_words = opinion_lexicon.negative()\n",
    "negative_words_set = set(opinion_lexicon.negative())\n",
    "#import requests\n",
    "#positive = set(requests.get('https://raw.githubusercontent.com/justingrimmer/WUSTL/master/positive-words.txt').text.split(';')[-1].split())\n",
    "#negative = set(requests.get('https://raw.githubusercontent.com/justingrimmer/WUSTL/master/negative-words.txt').text.split(';')[-1].split())\n",
    "#len(negative&negative_words_set),len(negative),len(negative_words_set)\n",
    "#negative_words_set-negative,negative-negative_words_set\n",
    "import random\n",
    "random.choice(negative_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%timeit 'fuck' in negative_words\n",
    "%timeit 'fuck' in negative_words_set # remember to lookup the lexicon in a set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.3333333333333333)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_words = set(opinion_lexicon.negative())\n",
    "positive_words = set(opinion_lexicon.positive())\n",
    "def match2lexicon(sentence,s):\n",
    "    matched = [w for w in sentence if w in s]\n",
    "    return matched\n",
    "def lexical_sentiment(sentence):\n",
    "    neg_sentence = match2lexicon(sentence,negative_words)\n",
    "    pos_sentence = match2lexicon(sentence,positive_words)\n",
    "    polarity = (len(pos_sentence)-len(neg_sentence))/len(sentence)\n",
    "    return polarity\n",
    "lexical_sentiment(['I','Love','You']),lexical_sentiment(['i','love','you']) # case-sensitive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "sample_sentences = nltk.sent_tokenize(' '.join(enron_df.sample(50).content.values))\n",
    "tokenized_sentences = [nltk.word_tokenize(sentence) for sentence in sample_sentences]\n",
    "\n",
    "polarity_sentences = [lexical_sentiment(sentence) for sentence in tokenized_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import afinn # another lexicon version\n",
    "Afinn = afinn.Afinn(language='en',emoticons=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "afinn_sentences = [Afinn.score(sentence) for sentence in sample_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEKCAYAAADuEgmxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBgAgGkEDABDt/wOejmMhE+Q5zwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(afinn_sentences,polarity_sentences)\n",
    "plt.xlabel('Afinn')\n",
    "plt.ylabel('Li Hue');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "** Rulebased **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "re.compile(r\"\\n    (?:\\n      [<>]?\\n      [:;=8]                     # eyes\\n      [\\-o\\*\\']?                 # optional nose\\n      [\\)\\]\\(\\[dDpP/\\:\\}\\{@\\|\\\\] # mouth\\n      |\\n      [\\)\\]\\(\\[dDpP/\\:\\}\\{@\\|\\\\] # mouth\\n      [\\-o\\*\\']?                 # optional nose\\n      [:;=8]                     # eyes\\n      [<>]?\\n      |\\n      <3                         # heart\\n    )\",\n",
       "re.IGNORECASE|re.UNICODE|re.VERBOSE)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "import nltk.sentiment\n",
    "nltk.sentiment.util.EMOTICON_RE\n",
    "#nltk.sentiment.util.HAPPY\n",
    "#nltk.sentiment.util.SAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.512, 'neu': 0.488, 'pos': 0.0, 'compound': -0.4847}\n",
      "Sentiment(polarity=-0.425, subjectivity=1.0)\n"
     ]
    }
   ],
   "source": [
    "sentences = ['You are so beautiful, to me','You are very beautiful, on the inside','You are not beautiful']\n",
    "print(sentiment_analyzer.polarity_scores(sentences[-1]))\n",
    "b = TextBlob(sentences[-1])\n",
    "print(b.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "textblob_sentences = [TextBlob(sentence).sentiment.polarity for sentence in sample_sentences]\n",
    "\n",
    "sentiment_analyzer = nltk.sentiment.SentimentIntensityAnalyzer() # vader sentiment analyzer. Lexicon and rulebased.\n",
    "vader_sentiment = [sentiment_analyzer.polarity_scores(sentence) for sentence in sample_sentences]\n",
    "vader_sentiment = [sentiment['pos']-sentiment['neg'] for sentiment in vader_sentiment]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f0830683080>"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD8CAYAAABzTgP2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make an interactive plot or sample discord between the sentiment models. \n",
    "plt.scatter(vader_sentiment,textblob_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "# Modelbased Information Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center> ** Lets bring in the big guns **<center>\n",
    "![](https://www.rei.com/media/2a65e55e-8a10-4f8a-87b9-00445c53140f?size=1020x510)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The field of natural language processing (NLP) have developed models for parsing natural language extracting relations and entities.\n",
    "\n",
    "Core tasks include: \n",
    "* 1)Tagging words by their part of speech (POS) to reveal the linguistic role they play in the sentence (e.g., Verb, Noun, Adjective, etc.);\n",
    "* 2) tagging words as named entities (NER) such as places or organizations; \n",
    "* 3) structuring or \"parsing\" sentences into nested phrases that are local to, describe or depend on one another; and \n",
    "* 4) extracting informational claims from those phrases, like the Subject-Verb-Object (SVO)\n",
    "\n",
    "NLTK can do this, however not with state-of-the-art results. So here we tap into other ressources especially the CoreNLP framework developed at Stanford by Christopher Manning and others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Named Entity Recognition (NER)\n",
    "To continue our example about extracting names, we can now compare it to state of the art methods for extracting entities. \n",
    "\n",
    "Important to note here, is that: we are way beyond Regular expressions. \n",
    "\n",
    "These are supervised models, trained to recognize entities, from position in sentence, and semantic knowledge about words built into latent representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(254, 284)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## STANFORDS IMPLEMENTATION\n",
    "stanford_entities = stanford.nerTagger.tag(nltk.word_tokenize(string_sample[0:10000]))\n",
    "## SPACYs implementation\n",
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "enron_processed_spacy = nlp(string_sample[0:10000])\n",
    "spacy_entities = enron_processed_spacy.ents\n",
    "len([ent for ent in stanford_entities if ent[1]!='O']),len(spacy_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('--', 'PERSON'),\n",
       " ('Sally', 'PERSON'),\n",
       " ('Marshall', 'PERSON'),\n",
       " ('Lucy', 'PERSON'),\n",
       " ('Miller', 'PERSON'),\n",
       " ('Leff', 'PERSON'),\n",
       " ('Dan', 'PERSON'),\n",
       " ('Hickerson', 'PERSON'),\n",
       " ('Gary', 'PERSON'),\n",
       " ('Malcolm', 'PERSON'),\n",
       " ('Rodney', 'PERSON'),\n",
       " ('Hughes', 'ORGANIZATION'),\n",
       " ('James', 'PERSON'),\n",
       " ('A.', 'PERSON'),\n",
       " ('Dimichele', 'PERSON'),\n",
       " ('Rich', 'PERSON'),\n",
       " ('Causey', 'PERSON'),\n",
       " ('Richard', 'PERSON'),\n",
       " ('Hermann', 'PERSON'),\n",
       " ('Robert', 'PERSON'),\n",
       " ('Rick', 'PERSON'),\n",
       " ('Beck', 'PERSON'),\n",
       " ('Sally', 'PERSON'),\n",
       " ('Haedicke', 'PERSON'),\n",
       " ('Mark', 'PERSON'),\n",
       " ('E.', 'PERSON'),\n",
       " ('Hayslett', 'PERSON'),\n",
       " ('Rod', 'PERSON'),\n",
       " ('Shaw', 'PERSON'),\n",
       " ('Eric', 'PERSON'),\n",
       " ('Collins', 'PERSON'),\n",
       " ('Angie', 'PERSON'),\n",
       " ('Hinojosa', 'PERSON'),\n",
       " ('Esmeralda', 'PERSON'),\n",
       " ('Zoch', 'PERSON'),\n",
       " ('Judy', 'PERSON'),\n",
       " ('Elbertson', 'PERSON'),\n",
       " ('Janette', 'PERSON'),\n",
       " ('Valdez', 'LOCATION'),\n",
       " ('Christina', 'PERSON'),\n",
       " ('Heathman', 'PERSON'),\n",
       " ('Karen', 'PERSON'),\n",
       " ('K.', 'PERSON'),\n",
       " ('Westbrook', 'PERSON'),\n",
       " ('Sharron', 'PERSON'),\n",
       " ('Alcantara', 'PERSON'),\n",
       " ('Ana', 'PERSON'),\n",
       " ('Collett', 'PERSON'),\n",
       " ('Crissy', 'PERSON'),\n",
       " ('Blackwood', 'PERSON'),\n",
       " ('Short', 'PERSON'),\n",
       " ('Carol', 'PERSON'),\n",
       " ('Post', 'ORGANIZATION'),\n",
       " ('Petition', 'ORGANIZATION'),\n",
       " ('Meeting', 'ORGANIZATION'),\n",
       " ('Enron', 'ORGANIZATION'),\n",
       " ('Wholesale', 'ORGANIZATION'),\n",
       " ('Meeting', 'ORGANIZATION'),\n",
       " ('Lucy', 'PERSON'),\n",
       " ('Marshall', 'PERSON'),\n",
       " ('Executive', 'ORGANIZATION'),\n",
       " ('Assistant', 'ORGANIZATION'),\n",
       " ('to', 'ORGANIZATION'),\n",
       " ('Jim', 'ORGANIZATION'),\n",
       " ('Fallon', 'ORGANIZATION'),\n",
       " ('Office', 'ORGANIZATION'),\n",
       " ('of', 'ORGANIZATION'),\n",
       " ('the', 'ORGANIZATION'),\n",
       " ('Chairman', 'ORGANIZATION'),\n",
       " ('Enron', 'ORGANIZATION'),\n",
       " ('Broadband', 'ORGANIZATION'),\n",
       " ('Services', 'ORGANIZATION'),\n",
       " ('Office', 'ORGANIZATION'),\n",
       " ('Kathy', 'PERSON'),\n",
       " ('Dana', 'PERSON'),\n",
       " ('Davis', 'PERSON'),\n",
       " ('Edith', 'PERSON'),\n",
       " ('Dana', 'PERSON'),\n",
       " ('DavisHOUECT', 'PERSON'),\n",
       " ('EdithErica', 'ORGANIZATION')]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "[ent for ent in stanford_entities if ent[1]!='O']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## These entities serves as important merge points for further analysis.\n",
    "e.g. geographical as we spoke about earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import geopy # install the geopy module: pip install geopy\n",
    "from geopy.geocoders import Nominatim\n",
    "geolocator = Nominatim()\n",
    "Counter([ent.label_ for ent in spacy_entities])\n",
    "for ent in spacy_entities:\n",
    "    if ent.label_=='GPE':\n",
    "        geocoded = geolocator.geocode(ent)\n",
    "        print(ent,geocoded,geocoded.latitude,geocoded.longitude)\n",
    "        \n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "But also people and organizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "persons_spacy = set()\n",
    "for ent in spacy_entities:\n",
    "    if ent.label_=='PERSON':\n",
    "        persons_spacy.add(str(ent))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54, 34, 16)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "persons_stanford = set([ent[0] for ent in stanford_entities if ent[1]=='PERSON'])\n",
    "len(persons_stanford),len(persons_spacy),len(persons_stanford&persons_spacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#persons_stanford&persons_spacy\n",
    "#persons_stanford"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Part-of-Speech (POS) tagging\n",
    "POS-tagging is about classifing the semantic role of each word in a sentence. \n",
    "The Stanford POS tagger uses the [Penn Treebank tag set]('http://repository.upenn.edu/cgi/viewcontent.cgi?article=1603&context=cis_reports') to POS tag words from input sentences. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "|#. |Tag |Description |\n",
    "|---|----|------------|\n",
    "|1.     |CC     |Coordinating conjunction\n",
    "|2.     |CD     |Cardinal number\n",
    "|3.     |DT     |Determiner\n",
    "|4.     |EX     |Existential there\n",
    "|5.     |FW     |Foreign word\n",
    "|6.     |IN     |Preposition or subordinating conjunction\n",
    "|7.     |JJ     |Adjective\n",
    "|8.     |JJR|   Adjective, comparative\n",
    "|9.     |JJS|   Adjective, superlative\n",
    "|10.|   LS      |List item marker\n",
    "|11.|   MD      |Modal\n",
    "|12.|   NN      |Noun, singular or mass\n",
    "|13.|   NNS     |Noun, plural\n",
    "|14.|   NNP     |Proper noun, singular\n",
    "|15.|   NNPS|   Proper noun, plural\n",
    "|16.|   PDT     |Predeterminer\n",
    "|17.|   POS     |Possessive ending\n",
    "|18.|   PRP     |Personal pronoun\n",
    "|19.|   PRP\\$|  Possessive pronoun\n",
    "|20.|   RB      |Adverb\n",
    "|21.|   RBR     |Adverb, comparative\n",
    "|22.|   RBS     |Adverb, superlative\n",
    "|23.|   RP      |Particle\n",
    "|24.|   SYM     |Symbol\n",
    "|25.|   TO      |to\n",
    "|26.|   UH      |Interjection\n",
    "|27.|   VB      |Verb, base form\n",
    "|28.|   VBD     |Verb, past tense\n",
    "|29.|   VBG     |Verb, gerund or present participle\n",
    "|30.|   VBN     |Verb, past participle\n",
    "|31.|   VBP     |Verb, non-3rd person singular present\n",
    "|32.|   VBZ     |Verb, 3rd person singular present\n",
    "|33.|   WDT     |Wh-determiner\n",
    "|34.|   WP      |Wh-pronoun\n",
    "|35.|   WP$     |Possessive wh-pronoun\n",
    "|36.|   WRB     |Wh-adverb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('I', 'PRP'), ('saw', 'VBD'), ('the', 'DT'), ('elephant', 'NN'), ('in', 'IN'), ('my', 'PRP$'), ('pajamas', 'NNS'), ('.', '.')], [('The', 'DT'), ('quick', 'JJ'), ('brown', 'JJ'), ('fox', 'NN'), ('jumped', 'VBD'), ('over', 'IN'), ('the', 'DT'), ('lazy', 'JJ'), ('dog', 'NN'), ('.', '.')], [('While', 'IN'), ('in', 'IN'), ('France', 'NNP'), (',', ','), ('Christine', 'NNP'), ('Lagarde', 'NNP'), ('discussed', 'VBD'), ('short-term', 'JJ'), ('stimulus', 'NN'), ('efforts', 'NNS'), ('in', 'IN'), ('a', 'DT'), ('recent', 'JJ'), ('interview', 'NN'), ('with', 'IN'), ('the', 'DT'), ('Wall', 'NNP'), ('Street', 'NNP'), ('Journal', 'NNP'), ('.', '.')], [('Trayvon', 'NNP'), ('Benjamin', 'NNP'), ('Martin', 'NNP'), ('was', 'VBD'), ('an', 'DT'), ('African', 'NNP'), ('American', 'NNP'), ('from', 'IN'), ('Miami', 'NNP'), ('Gardens', 'NNP'), (',', ','), ('Florida', 'NNP'), (',', ','), ('who', 'WP'), (',', ','), ('at', 'IN'), ('17', 'CD'), ('years', 'NNS'), ('old', 'JJ'), (',', ','), ('was', 'VBD'), ('fatally', 'RB'), ('shot', 'VBN'), ('by', 'IN'), ('George', 'NNP'), ('Zimmerman', 'NNP'), (',', ','), ('a', 'DT'), ('neighborhood', 'NN'), ('watch', 'NN'), ('volunteer', 'NN'), (',', ','), ('in', 'IN'), ('Sanford', 'NNP'), (',', ','), ('Florida', 'NNP'), ('.', '.')], [('Buffalo', 'NNP'), ('buffalo', 'NN'), ('Buffalo', 'NNP'), ('buffalo', 'NN'), ('buffalo', 'NN'), ('buffalo', 'NN'), ('Buffalo', 'NNP'), ('buffalo', 'NN')]]\n"
     ]
    }
   ],
   "source": [
    "text = ['I saw the elephant in my pajamas.', 'The quick brown fox jumped over the lazy dog.', 'While in France, Christine Lagarde discussed short-term stimulus efforts in a recent interview with the Wall Street Journal.', 'Trayvon Benjamin Martin was an African American from Miami Gardens, Florida, who, at 17 years old, was fatally shot by George Zimmerman, a neighborhood watch volunteer, in Sanford, Florida.', 'Buffalo buffalo Buffalo buffalo buffalo buffalo Buffalo buffalo']\n",
    "tokenized_text = [nltk.word_tokenize(t) for t in text]\n",
    "pos_sents = stanford.postTagger.tag_sents(tokenized_text)\n",
    "print(pos_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Under these conditions it might work reasonably well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# lets see what the different persons are doing and saying.\n",
    "pos_tags = stanford.postTagger.tag_sents([nltk.word_tokenize(sent) for sent in nltk.sent_tokenize(string_sample[0:25000])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# other pos-taggers\n",
    "nltk.pos_tag()\n",
    "b = TextBlob(' '.join(enron_df.iloc[0:10].content))\n",
    "b.tags\n",
    "for token in enron_processed_spacy[0:10]:\n",
    "    print(token.text,token.ent_type,token.ent_type_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'--': ['settle', 'changing', 'build', 'been'],\n",
       " '-- -- -- -- -- -- -- -- -- -- --': ['Forwarded', 'Forwarded', 'Forwarded'],\n",
       " 'Davis': ['following', 'said', 'began', 'had', 'was', 'kicked', 'resolving'],\n",
       " 'Robert': ['Buy'],\n",
       " 'Shaw': ['took']}"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verbs = set(['VB','VBD','VBN','VBG'])\n",
    "def get_person2kind(word_classes,skips_allowed=3):\n",
    "    person2kind = {}\n",
    "    for sentence in pos_tags:\n",
    "        active = False\n",
    "        for word,kind in sentence:\n",
    "            if word in persons_stanford:\n",
    "                if active and skip==0:\n",
    "                    person+=(' '+word)\n",
    "                    continue\n",
    "                active = True\n",
    "                skip = 0\n",
    "                person = word\n",
    "                continue\n",
    "            elif active:\n",
    "                if kind in word_classes:\n",
    "                    if person in person2kind:\n",
    "                        person2kind[person].append(word)\n",
    "                    else:\n",
    "                        person2kind[person] = [word]\n",
    "                    active = False\n",
    "                skip+=1\n",
    "                if skip>skips_allowed:\n",
    "                    active = False\n",
    "    return person2kind\n",
    "get_person2kind(verbs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "While the Core objective in NLP, and AI research more specifically, is to develop generic models, that can handle almost any situation. \n",
    "\n",
    "However one should remember that they were trained on specific samples and datasets. While they might be highly effective under certain conditions, others might yield them useless."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Subject-Verb-Object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {
    "collapsed": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "ieDF = stanford.openIE(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>certainty</th>\n",
       "      <th>subject</th>\n",
       "      <th>verb</th>\n",
       "      <th>object</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.518918</td>\n",
       "      <td>any/dti irregularities/nns</td>\n",
       "      <td>took/vbd</td>\n",
       "      <td>place/nn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>The/at Fulton/np-tl County/nn-tl Grand/jj-tl J...</td>\n",
       "      <td>has</td>\n",
       "      <td>np $ recent/jj primary/nn election/nn produced...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>The/at September-October/np term/nn jury/nn ha...</td>\n",
       "      <td>of/in</td>\n",
       "      <td>possible/jj irregularities/nns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>The/at September-October/np term/nn jury/nn ha...</td>\n",
       "      <td>of/in</td>\n",
       "      <td>possible/jj irregularities/nns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>The/at September-October/np term/nn jury/nn ha...</td>\n",
       "      <td>of/in</td>\n",
       "      <td>irregularities/nns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>The/at September-October/np term/nn jury/nn ha...</td>\n",
       "      <td>of/in</td>\n",
       "      <td>irregularities/nns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>did/dod find/vb</td>\n",
       "      <td>that/cs</td>\n",
       "      <td>many/ap of/in Georgia 's np $ registration/nn ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>many/ap of/in Georgia</td>\n",
       "      <td>has</td>\n",
       "      <td>np $ registration/nn and/cc election/nn laws/n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>did/dod find/vb</td>\n",
       "      <td>that/cs</td>\n",
       "      <td>many/ap of/in Georgia 's np and/cc election/nn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>did/dod find/vb</td>\n",
       "      <td>that/cs</td>\n",
       "      <td>many/ap of/in Georgia 's np and/cc laws/nns ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>did/dod find/vb</td>\n",
       "      <td>that/cs</td>\n",
       "      <td>many/ap of/in Georgia 's np and/cc laws/nns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>did/dod find/vb</td>\n",
       "      <td>that/cs</td>\n",
       "      <td>many/ap of/in Georgia 's np $ registration/nn ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>did/dod find/vb</td>\n",
       "      <td>that/cs</td>\n",
       "      <td>many/ap of/in Georgia 's np $ registration/nn ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>did/dod find/vb</td>\n",
       "      <td>that/cs</td>\n",
       "      <td>many/ap of/in Georgia 's np $ registration/nn ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>did/dod find/vb</td>\n",
       "      <td>that/cs</td>\n",
       "      <td>many/ap of/in Georgia 's np and/cc election/nn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>It/pps</td>\n",
       "      <td>recommended/vbd</td>\n",
       "      <td>that/cs legislators/nns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>It/pps</td>\n",
       "      <td>recommended/vbd</td>\n",
       "      <td>that/cs Fulton/np legislators/nns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>The/at grand/jj jury/nn commented/vbd on/in a/...</td>\n",
       "      <td>them/ppo the/at</td>\n",
       "      <td>Atlanta/np and/cc Fulton/np-tl County/nn-tl pu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>these/dts</td>\n",
       "      <td>two/cd</td>\n",
       "      <td>offices/nns should/md be/be combined/vbn to/to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>believes/vbz</td>\n",
       "      <td>two/cd</td>\n",
       "      <td>offices/nns should/md be/be combined/vbn to/to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>these/dts</td>\n",
       "      <td>two/cd</td>\n",
       "      <td>offices/nns be/be combined/vbn to/to achieve/v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>these/dts</td>\n",
       "      <td>two/cd</td>\n",
       "      <td>offices/nns should/md be/be combined/vbn to/to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>these/dts</td>\n",
       "      <td>two/cd</td>\n",
       "      <td>offices/nns be/be combined/vbn to/to achieve/v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>believes/vbz</td>\n",
       "      <td>two/cd</td>\n",
       "      <td>offices/nns be/be combined/vbn to/to achieve/v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>believes/vbz</td>\n",
       "      <td>two/cd</td>\n",
       "      <td>offices/nns be/be combined/vbn to/to achieve/v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>believes/vbz</td>\n",
       "      <td>two/cd</td>\n",
       "      <td>offices/nns should/md be/be combined/vbn to/to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.705757</td>\n",
       "      <td>lacking/vbg in/in experienced/vbn clerical/jj ...</td>\n",
       "      <td>as/cs</td>\n",
       "      <td>a/at result/nn of/in city/nn personnel/nns pol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.705757</td>\n",
       "      <td>is/bez lacking/vbg in/in experienced/vbn cleri...</td>\n",
       "      <td>as/cs</td>\n",
       "      <td>a/at result/nn of/in city/nn personnel/nns pol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>take/vb steps/nns</td>\n",
       "      <td>to/to</td>\n",
       "      <td>remedy/vb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>steps/nns</td>\n",
       "      <td>to/to</td>\n",
       "      <td>remedy/vb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>his/pp year/nn as/cs</td>\n",
       "      <td>a/at</td>\n",
       "      <td>legislator/nn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>in/in his/pp $ year/nn as/cs</td>\n",
       "      <td>a/at</td>\n",
       "      <td>there/ex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>$ 13th/od year/nn as/cs</td>\n",
       "      <td>a/at</td>\n",
       "      <td>legislator/nn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>in/in his/pp year/nn as/cs</td>\n",
       "      <td>a/at</td>\n",
       "      <td>legislator/nn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>his/pp $ 13th/od year/nn as/cs</td>\n",
       "      <td>a/at</td>\n",
       "      <td>said/vbd there/ex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>in/in year/nn as/cs</td>\n",
       "      <td>a/at</td>\n",
       "      <td>said/vbd there/ex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>year/nn as/cs</td>\n",
       "      <td>a/at</td>\n",
       "      <td>said/vbd there/ex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>his/pp $ year/nn as/cs</td>\n",
       "      <td>a/at</td>\n",
       "      <td>there/ex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>in/in his/pp $ year/nn as/cs</td>\n",
       "      <td>a/at</td>\n",
       "      <td>legislator/nn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>his/pp $ 13th/od year/nn as/cs</td>\n",
       "      <td>a/at</td>\n",
       "      <td>legislator/nn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>in/in $ year/nn as/cs</td>\n",
       "      <td>a/at</td>\n",
       "      <td>legislator/nn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>in/in his/pp year/nn as/cs</td>\n",
       "      <td>a/at</td>\n",
       "      <td>there/ex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>none/pn of/in Georgia</td>\n",
       "      <td>has</td>\n",
       "      <td>np $ congressmen/nns specifically/rb asked/vbd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>The/at resolution/nn</td>\n",
       "      <td>into/in the/at</td>\n",
       "      <td>House/nn-tl hopper/nn Friday/nr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>It/pps</td>\n",
       "      <td>says/vbz</td>\n",
       "      <td>that/cs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>who/wps</td>\n",
       "      <td>defeated/vbd</td>\n",
       "      <td>Felix/np Bush/np a/at school/nn principal/nn a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>who/wps</td>\n",
       "      <td>defeated/vbd</td>\n",
       "      <td>Felix/np Bush/np a/at school/nn principal/nn a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>who/wps</td>\n",
       "      <td>defeated/vbd</td>\n",
       "      <td>Felix/np Bush/np</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>cd votes/nns</td>\n",
       "      <td>in/in</td>\n",
       "      <td>Saturday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>veiled/vbn threats/nns</td>\n",
       "      <td>of/in</td>\n",
       "      <td>violence/nn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>It/pps</td>\n",
       "      <td>was/bedz</td>\n",
       "      <td>marked/vbn by/in controversy/nn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>and/cc veiled/vbn threats/nns</td>\n",
       "      <td>of/in</td>\n",
       "      <td>violence/nn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>would/md be/be irregularities/nns</td>\n",
       "      <td>at/in the/at</td>\n",
       "      <td>and/cc Williams/np got/vbd himself/ppl a/at pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>be/be irregularities/nns</td>\n",
       "      <td>at/in the/at</td>\n",
       "      <td>Williams/np got/vbd himself/ppl a/at permit/nn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>would/md be/be irregularities/nns</td>\n",
       "      <td>at/in the/at</td>\n",
       "      <td>polls/nns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>be/be irregularities/nns</td>\n",
       "      <td>at/in the/at</td>\n",
       "      <td>polls/nns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>would/md be/be irregularities/nns</td>\n",
       "      <td>at/in the/at</td>\n",
       "      <td>Williams/np got/vbd himself/ppl a/at permit/nn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>be/be irregularities/nns</td>\n",
       "      <td>at/in the/at</td>\n",
       "      <td>and/cc Williams/np got/vbd himself/ppl a/at pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>Sheriff/nn-tl Felix/np Tabb/np said/vbd</td>\n",
       "      <td>his/pp</td>\n",
       "      <td>promise/nn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>Felix/np Tabb/np said/vbd</td>\n",
       "      <td>his/pp</td>\n",
       "      <td>promise/nn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>333 rows Ã 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     certainty                                            subject  \\\n",
       "0     0.518918                         any/dti irregularities/nns   \n",
       "1     1.000000  The/at Fulton/np-tl County/nn-tl Grand/jj-tl J...   \n",
       "2     1.000000  The/at September-October/np term/nn jury/nn ha...   \n",
       "3     1.000000  The/at September-October/np term/nn jury/nn ha...   \n",
       "4     1.000000  The/at September-October/np term/nn jury/nn ha...   \n",
       "5     1.000000  The/at September-October/np term/nn jury/nn ha...   \n",
       "6     1.000000                                    did/dod find/vb   \n",
       "7     1.000000                              many/ap of/in Georgia   \n",
       "8     1.000000                                    did/dod find/vb   \n",
       "9     1.000000                                    did/dod find/vb   \n",
       "10    1.000000                                    did/dod find/vb   \n",
       "11    1.000000                                    did/dod find/vb   \n",
       "12    1.000000                                    did/dod find/vb   \n",
       "13    1.000000                                    did/dod find/vb   \n",
       "14    1.000000                                    did/dod find/vb   \n",
       "15    1.000000                                             It/pps   \n",
       "16    1.000000                                             It/pps   \n",
       "17    1.000000  The/at grand/jj jury/nn commented/vbd on/in a/...   \n",
       "18    1.000000                                          these/dts   \n",
       "19    1.000000                                       believes/vbz   \n",
       "20    1.000000                                          these/dts   \n",
       "21    1.000000                                          these/dts   \n",
       "22    1.000000                                          these/dts   \n",
       "23    1.000000                                       believes/vbz   \n",
       "24    1.000000                                       believes/vbz   \n",
       "25    1.000000                                       believes/vbz   \n",
       "26    0.705757  lacking/vbg in/in experienced/vbn clerical/jj ...   \n",
       "27    0.705757  is/bez lacking/vbg in/in experienced/vbn cleri...   \n",
       "28    1.000000                                  take/vb steps/nns   \n",
       "29    1.000000                                          steps/nns   \n",
       "..         ...                                                ...   \n",
       "303   1.000000                               his/pp year/nn as/cs   \n",
       "304   1.000000                       in/in his/pp $ year/nn as/cs   \n",
       "305   1.000000                            $ 13th/od year/nn as/cs   \n",
       "306   1.000000                         in/in his/pp year/nn as/cs   \n",
       "307   1.000000                     his/pp $ 13th/od year/nn as/cs   \n",
       "308   1.000000                                in/in year/nn as/cs   \n",
       "309   1.000000                                      year/nn as/cs   \n",
       "310   1.000000                             his/pp $ year/nn as/cs   \n",
       "311   1.000000                       in/in his/pp $ year/nn as/cs   \n",
       "312   1.000000                     his/pp $ 13th/od year/nn as/cs   \n",
       "313   1.000000                              in/in $ year/nn as/cs   \n",
       "314   1.000000                         in/in his/pp year/nn as/cs   \n",
       "315   1.000000                              none/pn of/in Georgia   \n",
       "316   1.000000                               The/at resolution/nn   \n",
       "317   1.000000                                             It/pps   \n",
       "318   1.000000                                            who/wps   \n",
       "319   1.000000                                            who/wps   \n",
       "320   1.000000                                            who/wps   \n",
       "321   1.000000                                       cd votes/nns   \n",
       "322   1.000000                             veiled/vbn threats/nns   \n",
       "323   1.000000                                             It/pps   \n",
       "324   1.000000                      and/cc veiled/vbn threats/nns   \n",
       "325   1.000000                  would/md be/be irregularities/nns   \n",
       "326   1.000000                           be/be irregularities/nns   \n",
       "327   1.000000                  would/md be/be irregularities/nns   \n",
       "328   1.000000                           be/be irregularities/nns   \n",
       "329   1.000000                  would/md be/be irregularities/nns   \n",
       "330   1.000000                           be/be irregularities/nns   \n",
       "331   1.000000            Sheriff/nn-tl Felix/np Tabb/np said/vbd   \n",
       "332   1.000000                          Felix/np Tabb/np said/vbd   \n",
       "\n",
       "                verb                                             object  \n",
       "0           took/vbd                                           place/nn  \n",
       "1                has  np $ recent/jj primary/nn election/nn produced...  \n",
       "2              of/in                     possible/jj irregularities/nns  \n",
       "3              of/in                     possible/jj irregularities/nns  \n",
       "4              of/in                                 irregularities/nns  \n",
       "5              of/in                                 irregularities/nns  \n",
       "6            that/cs  many/ap of/in Georgia 's np $ registration/nn ...  \n",
       "7                has  np $ registration/nn and/cc election/nn laws/n...  \n",
       "8            that/cs  many/ap of/in Georgia 's np and/cc election/nn...  \n",
       "9            that/cs  many/ap of/in Georgia 's np and/cc laws/nns ar...  \n",
       "10           that/cs        many/ap of/in Georgia 's np and/cc laws/nns  \n",
       "11           that/cs  many/ap of/in Georgia 's np $ registration/nn ...  \n",
       "12           that/cs  many/ap of/in Georgia 's np $ registration/nn ...  \n",
       "13           that/cs  many/ap of/in Georgia 's np $ registration/nn ...  \n",
       "14           that/cs  many/ap of/in Georgia 's np and/cc election/nn...  \n",
       "15   recommended/vbd                            that/cs legislators/nns  \n",
       "16   recommended/vbd                  that/cs Fulton/np legislators/nns  \n",
       "17   them/ppo the/at  Atlanta/np and/cc Fulton/np-tl County/nn-tl pu...  \n",
       "18            two/cd  offices/nns should/md be/be combined/vbn to/to...  \n",
       "19            two/cd  offices/nns should/md be/be combined/vbn to/to...  \n",
       "20            two/cd  offices/nns be/be combined/vbn to/to achieve/v...  \n",
       "21            two/cd  offices/nns should/md be/be combined/vbn to/to...  \n",
       "22            two/cd  offices/nns be/be combined/vbn to/to achieve/v...  \n",
       "23            two/cd  offices/nns be/be combined/vbn to/to achieve/v...  \n",
       "24            two/cd  offices/nns be/be combined/vbn to/to achieve/v...  \n",
       "25            two/cd  offices/nns should/md be/be combined/vbn to/to...  \n",
       "26             as/cs  a/at result/nn of/in city/nn personnel/nns pol...  \n",
       "27             as/cs  a/at result/nn of/in city/nn personnel/nns pol...  \n",
       "28             to/to                                          remedy/vb  \n",
       "29             to/to                                          remedy/vb  \n",
       "..               ...                                                ...  \n",
       "303             a/at                                      legislator/nn  \n",
       "304             a/at                                           there/ex  \n",
       "305             a/at                                      legislator/nn  \n",
       "306             a/at                                      legislator/nn  \n",
       "307             a/at                                  said/vbd there/ex  \n",
       "308             a/at                                  said/vbd there/ex  \n",
       "309             a/at                                  said/vbd there/ex  \n",
       "310             a/at                                           there/ex  \n",
       "311             a/at                                      legislator/nn  \n",
       "312             a/at                                      legislator/nn  \n",
       "313             a/at                                      legislator/nn  \n",
       "314             a/at                                           there/ex  \n",
       "315              has  np $ congressmen/nns specifically/rb asked/vbd...  \n",
       "316   into/in the/at                    House/nn-tl hopper/nn Friday/nr  \n",
       "317         says/vbz                                            that/cs  \n",
       "318     defeated/vbd  Felix/np Bush/np a/at school/nn principal/nn a...  \n",
       "319     defeated/vbd  Felix/np Bush/np a/at school/nn principal/nn a...  \n",
       "320     defeated/vbd                                   Felix/np Bush/np  \n",
       "321            in/in                                           Saturday  \n",
       "322            of/in                                        violence/nn  \n",
       "323         was/bedz                    marked/vbn by/in controversy/nn  \n",
       "324            of/in                                        violence/nn  \n",
       "325     at/in the/at  and/cc Williams/np got/vbd himself/ppl a/at pe...  \n",
       "326     at/in the/at  Williams/np got/vbd himself/ppl a/at permit/nn...  \n",
       "327     at/in the/at                                          polls/nns  \n",
       "328     at/in the/at                                          polls/nns  \n",
       "329     at/in the/at  Williams/np got/vbd himself/ppl a/at permit/nn...  \n",
       "330     at/in the/at  and/cc Williams/np got/vbd himself/ppl a/at pe...  \n",
       "331           his/pp                                         promise/nn  \n",
       "332           his/pp                                         promise/nn  \n",
       "\n",
       "[333 rows x 4 columns]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ieDF#.object#.apply(lambda x: x.split('/')[:-1:2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_sample = stanford.postTagger.tag_sents([nltk.word_tokenize(sentence) for sentence in nltk.sent_tokenize(enron_sample[0:20000])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NTarget = 'JJ'\n",
    "#Word = ''\n",
    "NResults = set()\n",
    "\n",
    "for sentence in pos_sample:\n",
    "    adj = False\n",
    "    for ent,kind in sentence:\n",
    "        if kind=='JJ':\n",
    "            adj = ent\n",
    "            continue\n",
    "        if adj:\n",
    "            if kind=='NN':\n",
    "                NResults.add((adj,ent))\n",
    "                adj=False\n",
    "            if kind=='.': # sentence ended\n",
    "                adj = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('11th', 'Time'),\n",
       " ('12-month', 'lease'),\n",
       " ('12-month', 'term'),\n",
       " ('Approximate', 'delta'),\n",
       " ('Customized', 'position'),\n",
       " ('above', 'project'),\n",
       " ('active', 'password'),\n",
       " ('additional', 'call'),\n",
       " ('annual/seasonal', 'supply'),\n",
       " ('appropriate', 'entity'),\n",
       " ('appropriate', 'folder'),\n",
       " ('bottom', 'grid'),\n",
       " ('changed', 'position'),\n",
       " ('collar/floor', 'price'),\n",
       " ('complete', 'list'),\n",
       " ('consolidated', 'position'),\n",
       " ('corresponding', 'term'),\n",
       " ('current', 'position'),\n",
       " ('difficult', 'time'),\n",
       " ('economic', 'impact'),\n",
       " ('electric', 'period'),\n",
       " ('entire', 'unit'),\n",
       " ('explicit', 'position'),\n",
       " ('fine', 'PM'),\n",
       " ('first', 'bullet'),\n",
       " ('fixed', 'kWh'),\n",
       " ('flexible', 'position'),\n",
       " ('formal', 'business'),\n",
       " ('forward', 'gas'),\n",
       " ('good', 'CPA'),\n",
       " ('good', 'communication'),\n",
       " ('high', 'level'),\n",
       " ('honest', 'trip'),\n",
       " ('individual', 'position'),\n",
       " ('individual', 'room'),\n",
       " ('informative', 'solution'),\n",
       " ('initial', 'set'),\n",
       " ('instantaneous', 'gamma'),\n",
       " ('interruptible', ')'),\n",
       " ('large', 'number'),\n",
       " ('likely', 'land'),\n",
       " ('main', 'view'),\n",
       " ('many', 'scope'),\n",
       " ('monthly', 'index'),\n",
       " ('much', 'time'),\n",
       " ('multifamily', 'moratorium'),\n",
       " ('national', 'customer'),\n",
       " ('natural', 'gas'),\n",
       " ('net', 'P'),\n",
       " ('new', 'deal'),\n",
       " ('new', 'position'),\n",
       " ('new', 'show'),\n",
       " ('original', 'deal'),\n",
       " ('other', 'capture'),\n",
       " ('other', 'floor'),\n",
       " ('other', 'information'),\n",
       " ('particular', 'order'),\n",
       " ('physical', 'TDS'),\n",
       " ('physical', 'gas'),\n",
       " ('physical/financial', 'transport'),\n",
       " ('possible', 'project'),\n",
       " ('prior', 'deal'),\n",
       " ('quiet', 'turn'),\n",
       " ('real', 'deal'),\n",
       " ('real-time', 'desk'),\n",
       " ('relative', 'importance'),\n",
       " ('round', 'table'),\n",
       " ('second', 'check'),\n",
       " ('serious', 'interest'),\n",
       " ('short', 'window'),\n",
       " ('similar', 'package'),\n",
       " ('single', 'buyer'),\n",
       " ('single', 'point'),\n",
       " ('single', 'set'),\n",
       " ('small', 'percent'),\n",
       " ('square', 'foot'),\n",
       " ('static', 'address'),\n",
       " ('top', 'grid')}"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "pattern = 'million|billion'\n",
    "\n",
    "spans = []\n",
    "for val in re.finditer(pattern,sample):\n",
    "    spans.append(val.span())\n",
    "number_words = set(['million','billion','thousands','trillion'])\n",
    "for sentence in nltk.sent_tokenize(sample):\n",
    "    tokenized_sentence = nltk.word_tokenize(sentence)\n",
    "    for num,word in enumerate(tokenized_sentence):\n",
    "        if word in number_words:\n",
    "            print(tokenized_sentence[num-1],word,tokenized_sentence[num+1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([('Federal', '', '')],\n",
       "  'Delete if you are an international student or a domestic student not interested in Federal financial aid.'),\n",
       " ([('Federal', '', ''),\n",
       "   ('July', '', ''),\n",
       "   ('Treasury', '', ''),\n",
       "   ('May', '', '')],\n",
       "  'The interest rates on Federal education loans are variable and change on July 1, based on the 91-day T-Bill rate from the last Treasury auction in May plus a statutory percentage add-on (1.7% in-school, 2.3% in repayment).'),\n",
       " ([('May', '', '')],\n",
       "  'That auction was on May 29, 2001, with a rate of 3.688%, which rounds to 3.69%.'),\n",
       " ([('July', '', ''),\n",
       "   ('In', '', ''),\n",
       "   ('Rate', 'Repayment', ''),\n",
       "   ('Repayment', 'Rate', ''),\n",
       "   ('Rate', 'Direct', ''),\n",
       "   ('Direct', 'Loans', ''),\n",
       "   ('Loans', '', ''),\n",
       "   ('Thus', '', '')],\n",
       "  'According to the formula, the new applicable interest rates are as follows effective July 1: In-School Rate Repayment Rate Direct Loans 5.39% 5.99% Thus, interest rates have dropped by 2.2% and are lower than they have been in many years.'),\n",
       " ([('July', '', '')],\n",
       "  'Students who have not yet consolidated their federal loans should consider consolidating after July 1 in order to lock in these low rates, even (especially) if they are still in school.'),\n",
       " ([('Mark', 'Kantrowitz', ''), ('Kantrowitz', '', ''), ('FinAid', '', '')],\n",
       "  'According to Mark Kantrowitz, publisher of FinAid.com, \"a student with $16,000 in debt who consolidates at 6.0% (5.99% rounded up to the nearest 1/8th of a point) will save $2,233.52 over the lifetime of the loan compared with consolidating at 8.25% (8.19% rounded up to the nearest 1/8th of a point).'),\n",
       " ([('It', '', ''), ('Fed', '', ''), ('May', '', '')],\n",
       "  '\"Caveat: It is possible that the Fed will continue to cut interest rates and that this will continue to be reflected in auction results, so that next May the rates will be even lower.'),\n",
       " ([('Fed', '', ''), ('May', '', '')],\n",
       "  'But there is also the risk that the Fed rate cuts will end, and that the rates next May will be higher.'),\n",
       " ([('July', '', ''), ('June', '', '')],\n",
       "  'Given that the current rates are the lowest in many years and the savings already substantial, the safest course of action is to consolidate after July 1, 2001 and before June 30, 2002.\"'),\n",
       " ([('September', '', '')],\n",
       "  'However, if you are planning to consolidate I would suggest doing so before September 30, 2001 to take advantage of an additional 0.8% interest rate reduction.'),\n",
       " ([('Word', '', '')],\n",
       "  'Refer to the first attached Word file for details on this and the consolidation process.'),\n",
       " ([('If', '', ''), ('Direct', 'Loan', ''), ('Loan', '', ''), ('Word', '', '')],\n",
       "  '*It is not too late to apply for 2001-2002 federal student loans* If you are a U.S. citizen or permanent resident and are interested in borrowing a 5.39% Direct Loan, you may still apply by following the instructions in the second attached Word file.'),\n",
       " ([('Loan', 'Consolidation', ''),\n",
       "   ('Consolidation', 'Eve', ''),\n",
       "   ('Eve', 'June', ''),\n",
       "   ('June', '', ''),\n",
       "   ('Director', '', ''),\n",
       "   ('Financial', 'Aid', ''),\n",
       "   ('Aid', '', ''),\n",
       "   ('MBA', 'Programs', ''),\n",
       "   ('Programs', 'Haas', ''),\n",
       "   ('Haas', 'School', ''),\n",
       "   ('School', '', ''),\n",
       "   ('Business', '', ''),\n",
       "   ('S420C', 'University', ''),\n",
       "   ('University', '', ''),\n",
       "   ('California', '', ''),\n",
       "   ('Berkeley', 'Berkeley', ''),\n",
       "   ('Berkeley', '', ''),\n",
       "   ('CA', '', ''),\n",
       "   ('Kim', '', ''),\n",
       "   ('Twanda', '', '')],\n",
       "  'Regards- debi - Loan Consolidation Eve June 2001.doc - 2001 haas fafsa guide eve.doc _____________________________ debi fidler Director of Financial Aid for MBA Programs Haas School of Business, S420C University of California, Berkeley Berkeley, CA 94720-1900 voice (510) 643-1680 fax (510) 643-6659 Kim, to speed things up, it is a good idea to cc: Twanda on all emails regarding agreements.'),\n",
       " ([('Kim', 'Melodick', ''),\n",
       "   ('Melodick', '', ''),\n",
       "   ('PM', 'To', ''),\n",
       "   ('To', '', ''),\n",
       "   ('Michelle', 'Cash', ''),\n",
       "   ('Cash', '', ''),\n",
       "   ('Subject', '', ''),\n",
       "   ('Don', 'Baughman', ''),\n",
       "   ('Baughman', 'Please', ''),\n",
       "   ('Please', '', ''),\n",
       "   ('Don', 'Baughman', ''),\n",
       "   ('Baughman', '', '')],\n",
       "  'michelle Kim Melodick 06/16/2000 05:21 PM To: Michelle Cash/HOU/ECT@ECT cc: Subject: Don Baughman Please prepare an executable employment agreement for Don Baughman.'),\n",
       " ([('DealBench', 'Development', ''),\n",
       "   ('Development', 'Methodology', ''),\n",
       "   ('Methodology', '', '')],\n",
       "  'Attached is the DealBench Development Methodology that we will be following to sure up the development effort.'),\n",
       " ([('Forwarded', '', ''),\n",
       "   ('Rob', 'Walls', ''),\n",
       "   ('Walls', '', ''),\n",
       "   ('PM', '', ''),\n",
       "   ('Bruce', 'Lundstrom', ''),\n",
       "   ('Lundstrom', '', ''),\n",
       "   ('Sent', '', ''),\n",
       "   ('Wendi', 'Hoelscher', ''),\n",
       "   ('Hoelscher', '', ''),\n",
       "   ('PM', 'To', ''),\n",
       "   ('To', '', ''),\n",
       "   ('Rob', 'Walls', ''),\n",
       "   ('Walls', '', ''),\n",
       "   ('Subject', '', ''),\n",
       "   ('Global', 'Assets', ''),\n",
       "   ('Assets', 'Legal', ''),\n",
       "   ('Legal', '', ''),\n",
       "   ('Rob', '', ''),\n",
       "   ('Attached', '', ''),\n",
       "   ('Randy', 'Young', ''),\n",
       "   ('Young', '', ''),\n",
       "   ('Sandeep', 'Katwala', ''),\n",
       "   ('Katwala', '', ''),\n",
       "   ('Mark', 'Haedicke', ''),\n",
       "   ('Haedicke', '', '')],\n",
       "  'Thanks, -John fyi ----- Forwarded by Rob Walls/NA/Enron on 11/28/2000 04:50 PM ----- Bruce Lundstrom@ENRON_DEVELOPMENT Sent by: Wendi Hoelscher@ENRON_DEVELOPMENT 11/28/2000 04:21 PM To: Rob Walls/NA/Enron@Enron cc: Subject: Global Assets Legal org chart Rob: Attached is a draft org chart previously sent to Randy Young, Sandeep Katwala and Mark Haedicke.'),\n",
       " ([('Bruce', 'Assuming', ''), ('Assuming', '', '')],\n",
       "  \"Thanks, Bruce Assuming today's payments get processed, the attached are payments for tomorrow.\"),\n",
       " ([('Delainey', '', ''),\n",
       "   ('Forwarded', '', ''),\n",
       "   ('David', 'W', ''),\n",
       "   ('Delainey', '', ''),\n",
       "   ('PM', '', ''),\n",
       "   ('From', '', ''),\n",
       "   ('Stuart', 'Zisman', ''),\n",
       "   ('Zisman', '', ''),\n",
       "   ('PM', 'To', ''),\n",
       "   ('To', '', ''),\n",
       "   ('Mark', 'E', ''),\n",
       "   ('Haedicke', '', ''),\n",
       "   ('David', 'W', ''),\n",
       "   ('Delainey', '', ''),\n",
       "   ('Mark', 'Metts', ''),\n",
       "   ('Metts', '', ''),\n",
       "   ('Jeffery', 'Ader', ''),\n",
       "   ('Ader', '', ''),\n",
       "   ('Michael', 'R', ''),\n",
       "   ('Brown', '', ''),\n",
       "   ('Stephen', 'Plauche', ''),\n",
       "   ('Plauche', '', ''),\n",
       "   ('Subject', '', ''),\n",
       "   ('Approval', '', ''),\n",
       "   ('Non', '', ''),\n",
       "   ('Provision', 'Pursuant', ''),\n",
       "   ('Pursuant', '', ''),\n",
       "   ('Interoffice', 'Memorandum', ''),\n",
       "   ('Memorandum', '', ''),\n",
       "   ('Jim', 'Derrick', ''),\n",
       "   ('Derrick', '', ''),\n",
       "   ('Enron', 'Attorneys', ''),\n",
       "   ('Attorneys', '', ''),\n",
       "   ('October', '', ''),\n",
       "   ('Enron', 'North', ''),\n",
       "   ('North', 'America', ''),\n",
       "   ('America', 'Corp', ''),\n",
       "   ('Corp', '', '')],\n",
       "  'Regards Delainey ---------------------- Forwarded by David W Delainey/HOU/ECT on 01/31/2001 03:45 PM --------------------------- From: Stuart Zisman on 01/31/2001 03:06 PM To: Mark E Haedicke/HOU/ECT@ECT, David W Delainey/HOU/ECT@ECT, Mark Metts/NA/Enron@Enron cc: Jeffery Ader/HOU/ECT@ECT, Michael R Brown/LON/ECT@ECT, Stephen Plauche/Corp/Enron@Enron Subject: Approval of a Non-Solicitation Provision Pursuant to an Interoffice Memorandum from Jim Derrick to all Enron Attorneys dated October 27, 1999, I am required to seek approval from each of you prior to signing off on a non-solicitation agreement which affects Enron North America Corp.'),\n",
       " ([('Niagara', 'Mohawk', ''),\n",
       "   ('Mohawk', '', ''),\n",
       "   ('Offer', 'Service', ''),\n",
       "   ('Service', '', '')],\n",
       "  'This non-solicitation agreement is being required by Niagara Mohawk in order to participate in its request for proposal both to outsource the management of its supply portfolio and to provide power to meet its \"Standard Offer Service\" load requirements for a term ending 12/31/06.'),\n",
       " ([('Interested', 'Party', ''),\n",
       "   ('Party', '', ''),\n",
       "   ('Enron', 'North', ''),\n",
       "   ('North', 'America', ''),\n",
       "   ('America', 'Corp', ''),\n",
       "   ('Corp', '', ''),\n",
       "   ('Niagara', 'Mohawk', ''),\n",
       "   ('Mohawk', '', ''),\n",
       "   ('Interested', 'Party', ''),\n",
       "   ('Party', '', ''),\n",
       "   ('Confidentiality', 'Agreement', ''),\n",
       "   ('Agreement', '', ''),\n",
       "   ('Niagara', 'Mohawk', ''),\n",
       "   ('Mohawk', '', ''),\n",
       "   ('Interested', 'Party', ''),\n",
       "   ('Party', '', ''),\n",
       "   ('Transaction', '', ''),\n",
       "   ('Interested', 'Party', ''),\n",
       "   ('Party', '', ''),\n",
       "   ('Interested', 'Party', ''),\n",
       "   ('Party', '', ''),\n",
       "   ('Interested', 'Party', ''),\n",
       "   ('Party', '', ''),\n",
       "   ('Niagara', 'Mohawk', ''),\n",
       "   ('Mohawk', '', '')],\n",
       "  'The proposed non-solicitation language reads as follows: \"The Interested Party [this is defined to be Enron North America Corp.] agrees that, without the prior written consent of Niagara Mohawk, the Interested Party will not for a period of eighteen (18) months from the effective date of this Confidentiality Agreement directly or indirectly solicit for employment any non-union individual who is now employed by Niagara Mohawk, its parent, or any of its affiliates or subsidiaries and who is identified by the Interested Party as a result of its evaluation or otherwise in connection with the Transaction; provided, however, that the Interested Party shall not be prohibited from (i) employing any such individual who contacts the Interested Party on his or her own initiative and without any direct or indirect solicitation by the Interested Party, and (ii) conducting generalized solicitations for employees (which solicitations are not specifically targeted at employees of Niagara Mohawk, its parent, or any of its affiliates or subsidiaries) through the use of media advertisements, professional search firms or otherwise.\"'),\n",
       " ([('Jeff', 'Ader', ''),\n",
       "   ('Ader', '', ''),\n",
       "   ('Michael', 'Brown', ''),\n",
       "   ('Brown', '', '')],\n",
       "  'If you have questions about the underlying commercial transaction, please call either Jeff Ader or Michael Brown.'),\n",
       " ([('Stuart', '', ''),\n",
       "   ('CGoering', '', ''),\n",
       "   ('NYISO_TECH_EXCHANGE', 'Discussion', ''),\n",
       "   ('Discussion', 'List', ''),\n",
       "   ('List', '', ''),\n",
       "   ('The', 'NYISO', ''),\n",
       "   ('NYISO', '', ''),\n",
       "   ('August', '', ''),\n",
       "   ('Real', '', ''),\n",
       "   ('Market', '', ''),\n",
       "   ('ECA20010608B', '', ''),\n",
       "   ('HQ', '', ''),\n",
       "   ('NE', '', ''),\n",
       "   ('OH', '', ''),\n",
       "   ('PJM', '', ''),\n",
       "   ('Prices', '', ''),\n",
       "   ('August', '', ''),\n",
       "   ('Day', '', ''),\n",
       "   ('Market', '', '')],\n",
       "  'Thanks Stuart http://www.oddtodd.com/ CGoering@nyiso.com writes to the NYISO_TECH_EXCHANGE Discussion List: The NYISO is reserving hours beginning 9:00, 10:00, and 12:00-18:00 in the August 13, 2001 Real-Time Market as well as the following hours per ECA20010608B to verify prices: HQ: 0:00-1:00, 4:00-7:00, 11:00, 15:00, 18:00, 21:00 NE: 0:00-1:00, 4:00-7:00, 11:00, 15:00, 18:00, 21:00 OH: 0:00-1:00, 4:00-7:00, 11:00, 15:00, 18:00, 21:00 PJM: 0:00-1:00, 4:00-7:00, 11:00, 15:00, 18:00, 21:00 Prices in the August 14, 2001 Day-Ahead Market are correct.'),\n",
       " ([('Wish', 'You', ''),\n",
       "   ('You', 'Could', ''),\n",
       "   ('Could', 'Copy', ''),\n",
       "   ('Copy', 'DVD', ''),\n",
       "   ('DVD', 'Movies', ''),\n",
       "   ('Movies', '', '')],\n",
       "  'This e-mail information is a copy of the official posting which can be found at the following address on our website: Wish You Could Copy DVD Movies?'),\n",
       " ([('You', 'Can', ''), ('Can', '', '')], 'Now You Can!'),\n",
       " ([('Here', 'For', ''),\n",
       "   ('For', 'Details', ''),\n",
       "   ('Details', '', ''),\n",
       "   ('Message', '', ''),\n",
       "   ('From', '', ''),\n",
       "   ('Cashion', '', ''),\n",
       "   ('Jim', 'Sent', ''),\n",
       "   ('Sent', '', ''),\n",
       "   ('Thursday', '', ''),\n",
       "   ('June', '', ''),\n",
       "   ('AM', 'To', ''),\n",
       "   ('To', '', ''),\n",
       "   ('Campbell', '', ''),\n",
       "   ('Larry', 'F', ''),\n",
       "   ('Subject', '', ''),\n",
       "   ('DEAL', '', ''),\n",
       "   ('DEAL', '', ''),\n",
       "   ('NY', 'TRANS', ''),\n",
       "   ('TRANS', 'ID', ''),\n",
       "   ('ID', '', ''),\n",
       "   ('NY', 'SHOWING', ''),\n",
       "   ('SHOWING', '', ''),\n",
       "   ('MW', 'WHILE', ''),\n",
       "   ('WHILE', 'ENPOWER', ''),\n",
       "   ('ENPOWER', 'IS', ''),\n",
       "   ('IS', 'SHOWING', ''),\n",
       "   ('SHOWING', '', ''),\n",
       "   ('MW', '', '')],\n",
       "  'Click Here For Details i changed it -----Original Message----- From: Cashion, Jim Sent: Thursday, June 28, 2001 10:49 AM To: Campbell, Larry F. Subject: 6/26 - DEAL 664367 6/26 - DEAL 664367, NY TRANS ID 5071111, NY SHOWING 2,963.82 MW WHILE ENPOWER IS SHOWING 2,679 MW')]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = ' '.join(enron_df.sample(10).content.values)\n",
    "pattern = '[A-Z][a-z]+\\,'\n",
    "explore_regex(pattern,sample)\n",
    "name_regex = re.compile(r\" ([A-Z]\\w+)(?= ([A-Z]\\w*))?([\\'s])?\")\n",
    "#name_pattern = '(([A-Z]{1}[a-z]+)( )*(?[A-Z]{1}[a-z]+))'\n",
    "names = []\n",
    "for sentence in nltk.sent_tokenize(' '.join(enron_df.sample(10).content.values)):\n",
    "    for subsentence in sentence.split('\\n'):\n",
    "        results = name_regex.findall(subsentence.strip()[1:])\n",
    "        if len(results)!=0:\n",
    "        #if results!=None:\n",
    "            names.append((results,subsentence))\n",
    "\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Albuquerque, NM 87113', None) ll Power Systems, Inc. > 8725 Pan American Frwy > Albuquerque, NM 87113 > 505-798-6424 > 50\n",
      "('Station, TX 77845', None) t 28th. I mailed it to 4303 Pate Rd. #29, College Station, TX 77845. I will go ahead an\n",
      "('Houston, TX 77024', None) resses for DSL lines: Hunter Shively 10545 Gawain Houston, TX 77024 713 461-4130 Philli\n",
      "('Houston, TX 77055', None) X 77024 713 461-4130 Phillip Allen 8855 Merlin Ct Houston, TX 77055 713 463-8626 Mike G\n",
      "('Houston, TX 77057', None)  77055 713 463-8626 Mike Grigsby 6201 Meadow Lake Houston, TX 77057 713 780-1022 Thanks\n",
      "('McLean, VA 22102-3303', '-3303') CN Power, Inc. 7926 Jones Branch Drive, Suite 630 McLean, VA 22102-3303 Phone (703)893-4330\n",
      "('McLean, VA 22102-3303', '-3303') CN Power, Inc. 7926 Jones Branch Drive, Suite 630 McLean, VA 22102-3303 Phone (703)893-4330\n",
      "('Austin, TX 78761-5427', '-5427') surance Agency, Inc 6000 N., Lamar P.O. Box 15427 Austin, TX 78761-5427 Policy #CBI420478 C\n",
      "('Sterling, VA 20164', None) elligence Press, Inc. 22648 Glenn Drive Suite 305 Sterling, VA 20164 tel: (703) 318-8848\n",
      "('Austin, TX 78761-5427', '-5427') surance Agency, Inc 6000 N., Lamar P.O. Box 15427 Austin, TX 78761-5427 Policy #CBI420478 C\n",
      "('Houston, TX 77055', None)  is 713-646-2391 Mailing address: 8855 Merlin Ct, Houston, TX 77055 Thank you, Phillip \n",
      "('Houston, TX 77002', None) d them to my home or office (1400 Smith, EB3210B, Houston, TX 77002). The broker is Jim\n",
      "('Houston, TX 77055', None) ay. Please send them to my house (8855 Merlin Ct, Houston, TX 77055). Call me if necess\n",
      "('DURANGO, CO 81301', None) 06NOV DOUBLETREE DURANGO 07NOV 501 CAMINO DEL RIO DURANGO, CO 81301 TELEPHONE: (970) 25\n",
      "('Station, TX 77845', None) t 28th. I mailed it to 4303 Pate Rd. #29, College Station, TX 77845. I will go ahead an\n",
      "('Houston, TX 77024', None) resses for DSL lines: Hunter Shively 10545 Gawain Houston, TX 77024 713 461-4130 Philli\n",
      "('Houston, TX 77055', None) X 77024 713 461-4130 Phillip Allen 8855 Merlin Ct Houston, TX 77055 713 463-8626 Mike G\n",
      "('Houston, TX 77057', None)  77055 713 463-8626 Mike Grigsby 6201 Meadow Lake Houston, TX 77057 713 780-1022 Thanks\n",
      "('McLean, VA 22102-3303', '-3303') CN Power, Inc. 7926 Jones Branch Drive, Suite 630 McLean, VA 22102-3303 Phone (703)893-4330\n",
      "('McLean, VA 22102-3303', '-3303') CN Power, Inc. 7926 Jones Branch Drive, Suite 630 McLean, VA 22102-3303 Phone (703)893-4330\n",
      "('Washington, DC 20006', None) onmental Strategies 1775 Eye Street, NW Suite 800 Washington, DC 20006 Phone: +(202) 466-9\n",
      "('Austin, TX 78761-5427', '-5427') surance Agency, Inc 6000 N., Lamar P.O. Box 15427 Austin, TX 78761-5427 Policy #CBI420478 C\n",
      "('Sterling, VA 20164', None) elligence Press, Inc. 22648 Glenn Drive Suite 305 Sterling, VA 20164 tel: (703) 318-8848\n"
     ]
    }
   ],
   "source": [
    "zipcode_pattern = '([^0-9[.\\,\\w]*)?([0-9]{5})(-[0-9]{4})?'\n",
    "zipcode_pattern = '([A-Z]+\\w+, [A-Z]{2} [0-9]{5}(-[0-9]{4})?)'\n",
    "for result in re.finditer(zipcode_pattern,sample):\n",
    "    start,stop = result.span()\n",
    "    print(result.groups(),sample[start-50:stop+20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['505-798-6424',\n",
       " '505-798-6050',\n",
       " '505-220-4129',\n",
       " '713-853-7107',\n",
       " '303-575-6490',\n",
       " '512-338-1119',\n",
       " '512-338-1110',\n",
       " '512-748-7495',\n",
       " '512-338-1103',\n",
       " '512-338-1119',\n",
       " '512-338-1110',\n",
       " '512-748-7495',\n",
       " '512-338-1103',\n",
       " '512-338-1119',\n",
       " '512-338-1110',\n",
       " '512-748-7495',\n",
       " '512-338-1103',\n",
       " '713-942-8436',\n",
       " '713-853-3304',\n",
       " '858-450-2554',\n",
       " '713-853-1411',\n",
       " '(713)853-7041',\n",
       " '713-853-5536',\n",
       " '0000000000',\n",
       " '0000000000',\n",
       " '713 646 2391',\n",
       " '251327 1595',\n",
       " '265229 1063',\n",
       " '713 461-4130',\n",
       " '713 463-8626',\n",
       " '713 780-1022',\n",
       " '713-853-7041',\n",
       " '(403) 974-6756',\n",
       " '(403) 974-6756',\n",
       " '713-853-7041',\n",
       " '713-853-1711',\n",
       " '713-646-3239',\n",
       " '(212) 686-6808',\n",
       " '(703)893-4330',\n",
       " '(703)893-4390',\n",
       " '(443)255-7699',\n",
       " '713-853-1803',\n",
       " '(703)893-4330',\n",
       " '(703)893-4390',\n",
       " '(443)255-7699',\n",
       " '713-853-1803',\n",
       " '713-853-1803',\n",
       " '888-271-0949',\n",
       " '(713) 853-9510',\n",
       " '(713) 853-9510',\n",
       " '888-271-0949',\n",
       " '713-853-1411',\n",
       " '713-853-7041',\n",
       " '713-853-1711',\n",
       " '(512)451-6551',\n",
       " '(503-464-8671',\n",
       " '(713) 853-7041',\n",
       " '(203) 355-5059',\n",
       " '713-853-7060',\n",
       " '713-853-7041',\n",
       " '713-853-7041',\n",
       " '713-853-7041',\n",
       " '713-853-7041',\n",
       " '(703) 318-8848',\n",
       " '(703) 318-0597',\n",
       " '713-853-7041',\n",
       " '713-410-4679',\n",
       " '512-930-5832',\n",
       " '0000000000',\n",
       " '(512) 338-1119',\n",
       " '(512)338-1103',\n",
       " '512-295-8052',\n",
       " '(512) 338-1119',\n",
       " '(512)338-1103',\n",
       " '713-853-7041',\n",
       " '(512)451-6551',\n",
       " '202-383-2147',\n",
       " '713-410-4679',\n",
       " '210-271-8386',\n",
       " '888-203-1112',\n",
       " '512-732-0009',\n",
       " '512-732-0010',\n",
       " '512-751-9728',\n",
       " '713-646-2391',\n",
       " '713-853-7041',\n",
       " '713-853-7041',\n",
       " '713-463-8626',\n",
       " '713-646-2391',\n",
       " '713-646-2391',\n",
       " '713-853-7041',\n",
       " '713-646-2391',\n",
       " '713-853-7041',\n",
       " '713 853-3170',\n",
       " '303 575 6478',\n",
       " '713-463-8626',\n",
       " '512-732-0009',\n",
       " '512-732-0010',\n",
       " '512-751-9728',\n",
       " '713-853-7041',\n",
       " '323-658-3874',\n",
       " '323-658-3872',\n",
       " '323-658-3872',\n",
       " '713-463-8626',\n",
       " '713-853-7041',\n",
       " '8774820206',\n",
       " '(713)463-8626',\n",
       " '713-853-7041',\n",
       " '713-464-2391',\n",
       " '713-410-4679',\n",
       " '713-463-8626',\n",
       " '713-853-7069',\n",
       " '713-464-2391',\n",
       " '713-502-9402',\n",
       " '713-667-5889',\n",
       " '713-781-5810',\n",
       " '(713) 853-1575',\n",
       " '(713) 646-3490',\n",
       " '(713) 853-1575',\n",
       " '(713) 646-3490',\n",
       " '(816) 234-4455',\n",
       " '713-410-4679',\n",
       " '713-410-4679',\n",
       " '503-294-9116',\n",
       " '713-463-8626',\n",
       " '713-410-4679',\n",
       " '713-780-1022',\n",
       " '713-408-6256',\n",
       " '713-667-5889',\n",
       " '713-502-9402',\n",
       " '(713)463-8626',\n",
       " '713-853-7041',\n",
       " '(713)781-5810',\n",
       " '(713)781-6614',\n",
       " '713-463-8626',\n",
       " '713-646-2391',\n",
       " '0000000000',\n",
       " '888-271-0949',\n",
       " '403-) 245-3340',\n",
       " '(970) 259-6580',\n",
       " '(713) 853-9510',\n",
       " '(713) 853-9510',\n",
       " '202-383-2147',\n",
       " '713-853-7041',\n",
       " '888-271-0949',\n",
       " '713-853-7041',\n",
       " '303-575-6490',\n",
       " '512-338-1119',\n",
       " '512-338-1110',\n",
       " '512-748-7495',\n",
       " '512-338-1103',\n",
       " '512-338-1119',\n",
       " '512-338-1110',\n",
       " '512-748-7495',\n",
       " '512-338-1103',\n",
       " '512-338-1119',\n",
       " '512-338-1110',\n",
       " '512-748-7495',\n",
       " '512-338-1103',\n",
       " '713-942-8436',\n",
       " '713-853-3304',\n",
       " '858-450-2554',\n",
       " '800-369-2834',\n",
       " '609-514-0870',\n",
       " '(713)853-7041',\n",
       " '713-853-5536',\n",
       " '0000000000',\n",
       " '0000000000',\n",
       " '713 646 2391',\n",
       " '251327 1595',\n",
       " '265229 1063',\n",
       " '713 461-4130',\n",
       " '713 463-8626',\n",
       " '713 780-1022',\n",
       " '(403) 974-6756',\n",
       " '(403) 974-6756',\n",
       " '713-853-7041',\n",
       " '512) 263-0177',\n",
       " '(800) 427-5747',\n",
       " '713-646-3239',\n",
       " '(212) 686-6808',\n",
       " '(703)893-4330',\n",
       " '(703)893-4390',\n",
       " '(443)255-7699',\n",
       " '713-853-1803',\n",
       " '(703)893-4330',\n",
       " '(703)893-4390',\n",
       " '(443)255-7699',\n",
       " '713-853-1803',\n",
       " '713-853-1803',\n",
       " '503-805-2117',\n",
       " '800-424-2908',\n",
       " '720-548-5700',\n",
       " '(202) 466-9176',\n",
       " '(202) 331-4717',\n",
       " '888-271-0949',\n",
       " '(713) 853-9510',\n",
       " '(713) 853-9510',\n",
       " '888-271-0949',\n",
       " '713-853-1411',\n",
       " '713-853-7041',\n",
       " '713-853-1711',\n",
       " '(512)451-6551',\n",
       " '(503-464-8671',\n",
       " '(713) 853-7041',\n",
       " '(203) 355-5059',\n",
       " '713-853-7060',\n",
       " '713-853-7041',\n",
       " '713-853-7041',\n",
       " '713-853-7041',\n",
       " '713-853-7041',\n",
       " '(703) 318-8848',\n",
       " '(703) 318-0597',\n",
       " '713-853-7041',\n",
       " '323-658-3874',\n",
       " '323-658-3872',\n",
       " '323-658-3872',\n",
       " '713-410-4679',\n",
       " '512-930-5832',\n",
       " '0000000000']"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tlf numbers.\n",
    "phone_regex = '(\\(?\\d{3}[\\- \\)]*\\d{3}[\\- ]*\\d{4})'\n",
    "re.findall(phone_regex,sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Danish ressources:\n",
    "* A very nice overview of Danish nlp ressources: http://www2.imm.dtu.dk/pubdb/views/edoc_download.php/6956/pdf/imm6956.pdf\n",
    "* The `polyglot module` (although hard to install) has support for danish among many other languages."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  },
  "toc": {
   "nav_menu": {
    "height": "384px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
